{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6e110d40",
      "metadata": {
        "id": "6e110d40"
      },
      "source": [
        "Using the main.ipynb for training Transformers was too chaotic for me. This file will be ONLY contain code that is absolutely necessary for finding out how to train the Transformer model."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# if \"preprocessing\" folder in current folders -> cd back to original folder\n",
        "%cd /content\n",
        "import os\n",
        "if os.path.exists(\"bsc-thesis\"):\n",
        "  # if bsc-thesis folder already exists; completely remove\n",
        "  !rm -rf bsc-thesis\n",
        "\n",
        "branch = \"main\"\n",
        "!git clone --branch $branch https://github.com/maviddoerdijk/bsc-thesis.git\n",
        "%cd bsc-thesis/src\n",
        "%ls"
      ],
      "metadata": {
        "id": "Jrv4ZsLMQKsm",
        "outputId": "ccc1467f-9e8f-480b-beca-9d3f2a1d4e72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Jrv4ZsLMQKsm",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'bsc-thesis'...\n",
            "remote: Enumerating objects: 211, done.\u001b[K\n",
            "remote: Counting objects: 100% (211/211), done.\u001b[K\n",
            "remote: Compressing objects: 100% (174/174), done.\u001b[K\n",
            "remote: Total 211 (delta 114), reused 94 (delta 32), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (211/211), 5.85 MiB | 7.78 MiB/s, done.\n",
            "Resolving deltas: 100% (114/114), done.\n",
            "/content/bsc-thesis/src\n",
            "\u001b[0m\u001b[01;34mbacktesting\u001b[0m/  \u001b[01;34mdata\u001b[0m/       main.py  \u001b[01;34mpreprocessing\u001b[0m/\n",
            "\u001b[01;34mconfig\u001b[0m/       main.ipynb  \u001b[01;34mmodels\u001b[0m/  \u001b[01;34mutils\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ta\n",
        "!pip install prophet\n",
        "!pip install pykalman\n",
        "!pip install PyWavelets"
      ],
      "metadata": {
        "id": "m8qoNvXjSTQR",
        "outputId": "f2ec2396-831a-484a-a501-ed271a6ba979",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "m8qoNvXjSTQR",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ta in /usr/local/lib/python3.11/dist-packages (0.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from ta) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from ta) (2.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->ta) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->ta) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->ta) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->ta) (1.17.0)\n",
            "Requirement already satisfied: prophet in /usr/local/lib/python3.11/dist-packages (1.1.6)\n",
            "Requirement already satisfied: cmdstanpy>=1.0.4 in /usr/local/lib/python3.11/dist-packages (from prophet) (1.2.5)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.11/dist-packages (from prophet) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from prophet) (3.10.0)\n",
            "Requirement already satisfied: pandas>=1.0.4 in /usr/local/lib/python3.11/dist-packages (from prophet) (2.2.2)\n",
            "Requirement already satisfied: holidays<1,>=0.25 in /usr/local/lib/python3.11/dist-packages (from prophet) (0.71)\n",
            "Requirement already satisfied: tqdm>=4.36.1 in /usr/local/lib/python3.11/dist-packages (from prophet) (4.67.1)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from prophet) (6.5.2)\n",
            "Requirement already satisfied: stanio<2.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from cmdstanpy>=1.0.4->prophet) (0.5.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from holidays<1,>=0.25->prophet) (2.8.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->prophet) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->prophet) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->prophet) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->prophet) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->prophet) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->prophet) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->prophet) (3.2.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.4->prophet) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.4->prophet) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil->holidays<1,>=0.25->prophet) (1.17.0)\n",
            "Requirement already satisfied: pykalman in /usr/local/lib/python3.11/dist-packages (0.10.1)\n",
            "Requirement already satisfied: numpy<3 in /usr/local/lib/python3.11/dist-packages (from pykalman) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from pykalman) (24.2)\n",
            "Requirement already satisfied: scikit-base<0.13.0 in /usr/local/lib/python3.11/dist-packages (from pykalman) (0.12.2)\n",
            "Requirement already satisfied: scipy<2.0.0 in /usr/local/lib/python3.11/dist-packages (from pykalman) (1.14.1)\n",
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.11/dist-packages (1.8.0)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from PyWavelets) (2.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Module imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from typing import Optional, Callable, Dict, Any\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Custom Imports\n",
        "from models.statistical_models import create_dataset\n",
        "from data.data_collection import gather_data\n",
        "from data.scraper import load_cached_etf_tickers\n",
        "from preprocessing.cointegration import find_cointegrated_pairs\n",
        "from preprocessing.data_preprocessing import filter_pairs_data\n",
        "from preprocessing.technical_indicators import combine_pairs_data\n",
        "from models.statistical_models import default_normalize\n",
        "from preprocessing.wavelet_denoising import wav_den\n",
        "from preprocessing.filters import step_1_filter_remove_nans, step_2_filter_liquidity"
      ],
      "metadata": {
        "id": "9Ybs2x7pSIae"
      },
      "id": "9Ybs2x7pSIae",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "startDateStr = '2008-10-01'\n",
        "endDateStr = '2018-10-02' # documentation said that endDateStr is exclusive for both yahoofinance and the original code, but actually printing the shapes showed otherwise..\n",
        "instrumentIdsNASDAQandNYSE = load_cached_etf_tickers()\n",
        "data = gather_data(startDateStr, endDateStr, instrumentIdsNASDAQandNYSE)\n",
        "data_close_filtered_1, data_open_filtered_1, data_high_filtered_1, data_low_filtered_1, data_vol_filtered_1, data_original_format_filtered_1 = step_1_filter_remove_nans(data['close'], data['open'], data['high'], data['low'], data['vol'], data)\n",
        "data_close_filtered_2, data_open_filtered_2, data_high_filtered_2, data_low_filtered_2, data_vol_filtered_2, data_original_format_filtered_2 = step_2_filter_liquidity(data_close_filtered_1, data_open_filtered_1, data_high_filtered_1, data_low_filtered_1, data_vol_filtered_1, data_original_format_filtered_1)\n",
        "\n",
        "scores, pvalues, pairs = find_cointegrated_pairs(data_original_format_filtered_2)\n",
        "pairs_data = {key:value[1]  for (key, value) in pairs.items()}\n",
        "pairs_data = sorted(pairs_data.items(), key=lambda x: x[1])\n",
        "pairs_data_filtered = filter_pairs_data(pairs_data) # filter based on cointegration in such a way that we can simply pick the highest pair of stocks in the list.\n",
        "# Extract the most highly cointegrated pairs\n",
        "ticker_a, ticker_b = pairs_data_filtered[0][0][0], pairs_data_filtered[0][0][1]\n",
        "pairs_timeseries_df = combine_pairs_data(data_close_filtered_2, data_open_filtered_2, data_high_filtered_2, data_low_filtered_2, data_vol_filtered_2, ticker_a, ticker_b)\n",
        "# Note about pairs_timeseries_df: the timeseries output on which we should train are found in the key \"Spread_Close\"\n",
        "# But, also the input features are the following keys: ['S1_rsi', 'S2_rsi', 'S1_mfi', 'S2_mfi', 'S1_adi', 'S2_adi', 'S1_vpt', 'S2_vpt', 'S1_atr', 'S2_atr', 'S1_bb_ma', 'S2_bb_ma', 'S1_adx', 'S2_adx', 'S1_ema', 'S2_ema', 'S1_macd', 'S2_macd', 'S1_dlr', 'S2_dlr']"
      ],
      "metadata": {
        "id": "lWichRMcQaq9",
        "outputId": "1829488c-4325-44fe-9b83-2fffe27c5a3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "lWichRMcQaq9",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  777 of 777 completed\n",
            "ERROR:yfinance:\n",
            "494 Failed downloads:\n",
            "ERROR:yfinance:['USCL', 'FPXE', 'TEKX', 'GLCR', 'MYMG', 'AMZU', 'TSMG', 'IBBQ', 'AVS', 'NIKL', 'CAFG', 'OZEM', 'URNJ', 'LDSF', 'GBUG', 'VPLS', 'FMTM', 'QOWZ', 'QDTY', 'FMED', 'ESPO', 'SPYQ', 'IVEG', 'MSFU', 'EYEG', 'AAPB', 'SDTY', 'OOQB', 'BSVO', 'MCHS', 'BSMQ', 'EGGQ', 'STNC', 'XBIL', 'LGCF', 'MYCN', 'GPIX', 'FDIV', 'NERD', 'AMDD', 'VGUS', 'DWUS', 'USVN', 'MSFL', 'GLDY', 'CRWL', 'TSYY', 'PABD', 'BRTR', 'LEXI', 'CARY', 'BUFC', 'UFO', 'WRND', 'WTMU', 'MYMI', 'VFLO', 'IBGA', 'XYZG', 'CA', 'DUKH', 'EMXF', 'BSCU', 'LDEM', 'WABF', 'INDH', 'GTR', 'BSCW', 'DMXF', 'MCDS', 'TPLS', 'CTEC', 'DVAL', 'GPIQ', 'UYLD', 'BLCR', 'EBI', 'MVLL', 'CLOD', 'RGTX', 'IBGK', 'PCMM', 'OBIL', 'BTF', 'TSL', 'TDI', 'ERNZ', 'CORO', 'QSML', 'WNDY', 'COPJ', 'QQQS', 'PQJL', 'ROE', 'CEFA', 'SMCL', 'WCBR', 'CCNR', 'MYCL', 'BSJW', 'AVUQ', 'ELIL', 'KBAB', 'BSCY', 'MOOD', 'ARVR', 'QSIX', 'RAYS', 'BCLO', 'PSWD', 'MYCG', 'CLSM', 'IHYF', 'CLOA', 'BSJR', 'MQQQ', 'SPAQ', 'FDFF', 'NZUS', 'TSLL', 'FEAT', 'MYCH', 'UTWY', 'ASMG', 'QHDG', 'ETHA', 'QQLV', 'SOLT', 'EVMT', 'TSLS', 'CALI', 'BSCX', 'BMAX', 'ALIL', 'NVDD', 'MBS', 'PATN', 'SKYU', 'INFR', 'LGRO', 'NSI', 'TTEQ', 'MYMH', 'AIPI', 'DYTA', 'TSMX', 'BKCH', 'ADBG', 'SARK', 'HYDR', 'AIRL', 'QQJG', 'DGCB', 'ABCS', 'HIMZ', 'QQQJ', 'AGIX', 'MULL', 'TUGN', 'UMMA', 'NVDL', 'DFGP', 'BSJV', 'BUG', 'SMCO', 'CANC', 'MEDX', 'AMDG', 'JPY', 'VRTL', 'BEEX', 'MODL', 'SOXQ', 'TSEL', 'FINE', 'OPTZ', 'ELIS', 'EVYM', 'NCIQ', 'AMDS', 'SMCX', 'BSMV', 'AFSC', 'MYMJ', 'PQOC', 'ORR', 'CONL', 'KPDD', 'VGSR', 'SMCZ', 'HECO', 'PLTU', 'YQQQ', 'BSMT', 'TSMU', 'DVOL', 'FDCF', 'FDIG', 'HEQQ', 'AVXC', 'SKRE', 'JMID', 'CRMG', 'IONX', 'DUKX', 'ZTEN', 'BKIV', 'BAFE', 'IBTP', 'QCLR', 'ERET', 'MUU', 'ZTOP', 'TCHI', 'CPLS', 'XCNY', 'JGLO', 'EHLS', 'TBIL', 'BSCT', 'ARMG', 'HCOW', 'GIND', 'BSMU', 'AGMI', 'NPFI', 'ZIPP', 'NCPB', 'BTGD', 'LIVR', 'TXSS', 'DYNI', 'FEPI', 'IBIT', 'LRND', 'QRMI', 'GQQQ', 'BSMW', 'GXDW', 'USSH', 'AOTG', 'RUNN', 'BSMP', 'SEIE', 'AMUU', 'TSLQ', 'DVQQ', 'IBTL', 'PABU', 'HLAL', 'FBOT', 'VOLT', 'ZTWO', 'BSJS', 'TEKY', 'FMUB', 'WBND', 'NATO', 'BUFM', 'BSJU', 'GGLS', 'HWAY', 'BSMS', 'IBTK', 'BTFX', 'QQQI', 'QYLG', 'FCTE', 'BSMY', 'TQQY', 'WTBN', 'UFIV', 'MAXI', 'USDX', 'BRKU', 'FBL', 'EWJV', 'HOOX', 'SMST', 'FMUN', 'MEMS', 'BEEZ', 'NFXS', 'UTEN', 'EKG', 'IBAT', 'APED', 'MYCM', 'GLOW', 'REIT', 'QCML', 'INRO', 'IBTG', 'BRKD', 'IBOT', 'CLOU', 'PDBA', 'PTIR', 'AMZD', 'BSCV', 'IBTQ', 'GGLL', 'IBTM', 'ALLW', 'BULD', 'SLVR', 'WCLD', 'QQQM', 'NVDU', 'BOTT', 'INTW', 'COIG', 'PALU', 'COPP', 'IBGB', 'COWG', 'WISE', 'FDTX', 'EMEQ', 'IBTJ', 'UTRE', 'IBTO', 'LFSC', 'GNOM', 'LITP', 'WTMY', 'PPI', 'HRTS', 'HIDE', 'SMRI', 'QTR', 'RDTL', 'SPRX', 'AMDL', 'TXUG', 'QBIG', 'TSLG', 'SMCF', 'TUG', 'PMBS', 'SEEM', 'DFGX', 'RKLX', 'NEWZ', 'VCRB', 'QQQY', 'EVSD', 'WINC', 'VBIL', 'HOOG', 'RAA', 'MYCK', 'NVDG', 'DTCR', 'BRHY', 'BDGS', 'MSFD', 'QQA', 'AVGX', 'USAF', 'BELT', 'GSIB', 'AMZZ', 'AOHY', 'HERD', 'TAX', 'XAIX', 'AUMI', 'RNEW', 'ZAP', 'YOKE', 'BGRN', 'AVL', 'TARK', 'IBTI', 'SPCY', 'USRD', 'PLTD', 'ABIG', 'JTEK', 'ESMV', 'FTGS', 'ELFY', 'CANQ', 'ENDW', 'MNTL', 'MKAM', 'JPEF', 'UTWO', 'QQQT', 'LAYS', 'TSPY', 'JEPQ', 'TDSC', 'PYPG', 'SIXG', 'XFIX', 'JDOC', 'QQQA', 'BRRR', 'IWTR', 'PBQQ', 'HERO', 'CHGX', 'QQQH', 'ETEC', 'SFLO', 'QBUF', 'UCYB', 'DIVD', 'BGRO', 'IBTF', 'BKWO', 'ECOW', 'QQQG', 'METD', 'FIVY', 'YSPY', 'IBGL', 'SPCX', 'MRAL', 'TMET', 'NVDS', 'ILIT', 'GFLW', 'ICOP', 'FICS', 'QNXT', 'KROP', 'REAI', 'OOSB', 'PANG', 'BSJT', 'KQQQ', 'ORCX', 'SUSL', 'ODDS', 'SPAM', 'UBRL', 'BRNY', 'HFSP', 'MSTX', 'DMAT', 'PSTR', 'SEIS', 'DAPP', 'UBND', 'MUD', 'UTHY', 'CONI', 'PEPS', 'IQQQ', 'MCSE', 'COWS', 'DECO', 'SOFX', 'PQAP', 'CZAR', 'MYCI', 'AVGB', 'ZTRE', 'CHPS', 'QTOP', 'IBTH', 'TAXE', 'CCSB', 'NIXT', 'TXUE', 'SOLZ', 'AQWA', 'WEEI', 'DLLL', 'IONL', 'HYBI', 'USXF', 'BITS', 'RDTY', 'MYCF', 'TSLR', 'MYCJ', 'JIVE', 'NUSB', 'AMID', 'TSMZ', 'BSMR', 'UPGR', 'THMZ', 'DEMZ', 'QQQP', 'WGMI', 'BABX', 'FLDB', 'PQJA', 'FDNI']: YFPricesMissingError('possibly delisted; no price data found  (1d 2008-10-01 -> 2018-10-02) (Yahoo error = \"Data doesn\\'t exist for startDate = 1222833600, endDate = 1538452800\")')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed 820 pairs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('MBB', 'SHY'),\n",
              " ('IGIB', 'DVY'),\n",
              " ('IGIB', 'ONEQ'),\n",
              " ('IGIB', 'IFGL'),\n",
              " ('IGIB', 'BBH'),\n",
              " ('IGIB', 'PDP'),\n",
              " ('IGIB', 'ACWX'),\n",
              " ('IGIB', 'PEY'),\n",
              " ('IGIB', 'TUR'),\n",
              " ('IGIB', 'SOXX'),\n",
              " ('IGIB', 'TLT'),\n",
              " ('IGIB', 'PHO'),\n",
              " ('IGIB', 'IUSG'),\n",
              " ('IGIB', 'PRFZ'),\n",
              " ('IGIB', 'PID'),\n",
              " ('IGIB', 'IJT'),\n",
              " ('IGIB', 'ACWI'),\n",
              " ('IGIB', 'AAXJ'),\n",
              " ('IGIB', 'SHV'),\n",
              " ('IGIB', 'PFF'),\n",
              " ('IGIB', 'PKW'),\n",
              " ('IGIB', 'IEI'),\n",
              " ('IGIB', 'RTH'),\n",
              " ('IGIB', 'QTEC'),\n",
              " ('IGIB', 'IGF'),\n",
              " ('IGIB', 'FEX'),\n",
              " ('IGIB', 'PPH'),\n",
              " ('IGIB', 'SHY'),\n",
              " ('IGIB', 'QQQ'),\n",
              " ('IGIB', 'PIE'),\n",
              " ('IGIB', 'IBB'),\n",
              " ('IGIB', 'PNQI'),\n",
              " ('IGIB', 'SMH'),\n",
              " ('IGIB', 'EMB'),\n",
              " ('DVY', 'PRFZ'),\n",
              " ('DVY', 'PKW'),\n",
              " ('IFGL', 'USIG'),\n",
              " ('IFGL', 'PFF'),\n",
              " ('IFGL', 'IGSB'),\n",
              " ('IFGL', 'EMB'),\n",
              " ('USIG', 'ACWX'),\n",
              " ('USIG', 'IUSV'),\n",
              " ('USIG', 'PEY'),\n",
              " ('USIG', 'TUR'),\n",
              " ('USIG', 'SOXX'),\n",
              " ('USIG', 'TLT'),\n",
              " ('USIG', 'PHO'),\n",
              " ('USIG', 'PID'),\n",
              " ('USIG', 'ACWI'),\n",
              " ('USIG', 'AAXJ'),\n",
              " ('USIG', 'SHV'),\n",
              " ('USIG', 'PFF'),\n",
              " ('USIG', 'PKW'),\n",
              " ('USIG', 'IEI'),\n",
              " ('USIG', 'QTEC'),\n",
              " ('USIG', 'IGF'),\n",
              " ('USIG', 'PPH'),\n",
              " ('USIG', 'SHY'),\n",
              " ('USIG', 'PIE'),\n",
              " ('USIG', 'IBB'),\n",
              " ('USIG', 'SMH'),\n",
              " ('USIG', 'EMB'),\n",
              " ('ACWX', 'AAXJ'),\n",
              " ('PEY', 'PRFZ'),\n",
              " ('PEY', 'FEX'),\n",
              " ('BND', 'PFF'),\n",
              " ('BND', 'SHY'),\n",
              " ('IUSG', 'IJT'),\n",
              " ('IUSG', 'PNQI'),\n",
              " ('PRFZ', 'ACWI'),\n",
              " ('PRFZ', 'IGF'),\n",
              " ('PRFZ', 'FEX'),\n",
              " ('IJT', 'PNQI'),\n",
              " ('SHV', 'PFF'),\n",
              " ('SHV', 'PKW'),\n",
              " ('SHV', 'IGSB'),\n",
              " ('SHV', 'IEI'),\n",
              " ('SHV', 'RTH'),\n",
              " ('SHV', 'QTEC'),\n",
              " ('SHV', 'IGF'),\n",
              " ('SHV', 'FEX'),\n",
              " ('SHV', 'PPH'),\n",
              " ('SHV', 'QQQ'),\n",
              " ('SHV', 'PIE'),\n",
              " ('SHV', 'IEF'),\n",
              " ('SHV', 'IBB'),\n",
              " ('SHV', 'PNQI'),\n",
              " ('SHV', 'SMH'),\n",
              " ('SHV', 'EMB'),\n",
              " ('PFF', 'IGSB'),\n",
              " ('PFF', 'EMB'),\n",
              " ('PKW', 'IGF'),\n",
              " ('IGSB', 'IEI'),\n",
              " ('IGSB', 'RTH'),\n",
              " ('IGSB', 'QTEC'),\n",
              " ('IGSB', 'IGF'),\n",
              " ('IGSB', 'FEX'),\n",
              " ('IGSB', 'PPH'),\n",
              " ('IGSB', 'SHY'),\n",
              " ('IGSB', 'QQQ'),\n",
              " ('IGSB', 'PIE'),\n",
              " ('IGSB', 'IEF'),\n",
              " ('IGSB', 'IBB'),\n",
              " ('IGSB', 'PNQI'),\n",
              " ('IGSB', 'SMH'),\n",
              " ('IGSB', 'EMB'),\n",
              " ('QTEC', 'SMH')]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set a bunch of variables based on the existing function `execute_kalman_workflow` (Note: Some are changed already)\n",
        "pairs_timeseries: pd.DataFrame = pairs_timeseries_df\n",
        "target_col: str = \"Spread_Close\"\n",
        "burn_in: int = 30 # we remove the first 30 elements, because the largest window used for technical indicators is\n",
        "train_frac: float = 0.90\n",
        "dev_frac: float = 0.05   # remaining part is test\n",
        "look_back: int = 1\n",
        "denoise_fn: Optional[Callable[[pd.Series], np.ndarray]] = wav_den\n",
        "scaler_factory: Callable[..., MinMaxScaler] = MinMaxScaler\n",
        "scaler_kwargs: Optional[Dict[str, Any]] = {\"feature_range\": (0, 1)}\n",
        "normalise_fn: Callable[[pd.Series], pd.Series] = default_normalize\n",
        "delta: float = 1e-3\n",
        "obs_cov_reg: float = 2.\n",
        "trans_cov_avg: float = 0.01\n",
        "obs_cov_avg: float = 1.\n",
        "return_datasets: bool = False\n",
        "verbose: bool = False"
      ],
      "metadata": {
        "id": "5Zq0luAneeoD"
      },
      "id": "5Zq0luAneeoD",
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def execute_transformer_workflow\n",
        "if not target_col in pairs_timeseries.columns:\n",
        "  raise KeyError(f\"pairs_timeseries must contain {target_col}\")\n",
        "\n",
        "# burn the first 30 elements\n",
        "pairs_timeseries_burned = pairs_timeseries.iloc[burn_in:].copy()\n",
        "\n",
        "total_len = len(pairs_timeseries_burned)\n",
        "train_size = int(total_len * train_frac)\n",
        "dev_size   = int(total_len * dev_frac)\n",
        "test_size  = total_len - train_size - dev_size # not used, but for clarity\n",
        "\n",
        "train = pairs_timeseries_burned[:train_size]\n",
        "dev   = pairs_timeseries_burned[train_size:train_size+dev_size] # aka validation\n",
        "test  = pairs_timeseries_burned[train_size+dev_size:]\n",
        "\n",
        "if verbose:\n",
        "    print(f\"Split sizes — train: {len(train)}, dev: {len(dev)}, test: {len(test)}\")\n",
        "\n",
        "if denoise_fn is not None: # denoise using wavelet denoising\n",
        "    train = pd.DataFrame({col: denoise_fn(train[col]) for col in train.columns}) # TODO: unsure whether dev and test should also be denoised?\n",
        "\n",
        "scaler = scaler_factory(**scaler_kwargs)\n",
        "trainX_untr, trainX, trainY_untr, trainY = create_dataset(train.values, scaler=scaler, look_back=look_back) # note: len(train) = len(trainX_unr) + 1, this could cause problems\n",
        "devX_untr,   devX,   devY_untr,   devY   = create_dataset(dev.values,  scaler=scaler, look_back=look_back)\n",
        "testX_untr,  testX,  testY_untr,  testY  = create_dataset(test.values, scaler=scaler, look_back=look_back)\n",
        "trainY_untr[:20]\n",
        "\n",
        "# To-do's before going on\n",
        "# TODO: Remove S1_close/open/high/low/volume, same for S2 (done in combine_pairs_data)\n",
        "# TODO: add removing/adding these as features to the ablation study.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7iJKFnTtfZ_l",
        "outputId": "2f05606b-2d1d-42cb-ff20-4bd227244b40"
      },
      "id": "7iJKFnTtfZ_l",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([27.81830352]),\n",
              " array([27.42025825]),\n",
              " array([25.9191175]),\n",
              " array([22.98625305]),\n",
              " array([20.5661885]),\n",
              " array([21.23151271]),\n",
              " array([24.11603916]),\n",
              " array([25.605551]),\n",
              " array([26.16966699]),\n",
              " array([26.46204422]),\n",
              " array([25.33065673]),\n",
              " array([25.72835342]),\n",
              " array([25.91998167]),\n",
              " array([25.70591191]),\n",
              " array([25.83366537]),\n",
              " array([26.33152235]),\n",
              " array([26.35160811]),\n",
              " array([26.2352556]),\n",
              " array([26.03820719]),\n",
              " array([25.75521362])]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some examples of outputs for understanding the form of the data better:\n",
        "\n",
        "`len(trainX_untr)`\n",
        "```\n",
        "2238\n",
        "```\n",
        "\n",
        "`len(trainX_untr[0])`\n",
        "```\n",
        "34\n",
        "```\n",
        "\n",
        "Context: The 34 features consist of\n",
        "* 10 technical indicators for both S1 and S2 (total 20)\n",
        "* S1_close/open/high/low/volume, same for S2 (total 10)\n",
        "* Pair spreads: close, open, high, low (total 4)\n",
        "\n",
        "\n",
        "`trainX_untr[0] `\n",
        "```\n",
        "array([ 2.76970068e+01,  4.91006247e+01,  2.89730484e+01,  4.91027293e+01,\n",
        "        2.89891358e+01,  4.91343834e+01,  2.60513431e+01,  4.87784465e+01,\n",
        "        5.03546207e+05,  7.43386097e+03,  4.49718063e+01,  5.82671806e+01,\n",
        "        5.75577766e+01,  8.28358144e+01,  7.59406546e+01,  3.92425336e+02,\n",
        "        1.05376719e+05, -9.14930577e+03,  1.56861725e+00,  7.63660812e-01,\n",
        "        2.85638197e+01,  4.83799321e+01,  8.30115861e+00,  2.65305580e+01,\n",
        "        2.84687992e+01,  4.85740999e+01,  2.27306259e-01,  4.38795633e-02,\n",
        "       -1.31033890e+00,  1.00654755e-01, -6.89227038e+00, -5.61453974e+00,\n",
        "       -5.72867758e+00, -8.18838280e+00])\n",
        "```\n",
        "\n",
        "`len(trainY_untr)`\n",
        "```\n",
        "2238\n",
        "```\n",
        "\n",
        "\n",
        "`len(trainY_untr)[0]`\n",
        "```\n",
        "1\n",
        "```\n",
        "\n",
        "`trainY_untr[0]`\n",
        "```\n",
        "array([27.81830352])\n",
        "```\n",
        "\n",
        "`trainY_untr[:20]`\n",
        "```\n",
        "[array([27.81830352]),\n",
        " array([27.42025825]),\n",
        " array([25.9191175]),\n",
        " array([22.98625305]),\n",
        " array([20.5661885]),\n",
        " array([21.23151271]),\n",
        " array([24.11603916]),\n",
        " array([25.605551]),\n",
        " array([26.16966699]),\n",
        " array([26.46204422]),\n",
        " array([25.33065673]),\n",
        " array([25.72835342]),\n",
        " array([25.91998167]),\n",
        " array([25.70591191]),\n",
        " array([25.83366537]),\n",
        " array([26.33152235]),\n",
        " array([26.35160811]),\n",
        " array([26.2352556]),\n",
        " array([26.03820719]),\n",
        " array([25.75521362])]\n",
        " ```"
      ],
      "metadata": {
        "id": "JHsrTP01tun3"
      },
      "id": "JHsrTP01tun3"
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}