{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# if \"preprocessing\" folder in current folders -> cd back to original folder\n",
        "%cd /content\n",
        "import os\n",
        "if os.path.exists(\"bsc-thesis\"):\n",
        "  # if bsc-thesis folder already exists; completely remove\n",
        "  !rm -rf bsc-thesis\n",
        "\n",
        "# cloning repo\n",
        "branch = \"main\"\n",
        "!git clone --branch $branch https://github.com/maviddoerdijk/bsc-thesis.git\n",
        "\n",
        "# moving into project dir\n",
        "%cd bsc-thesis/src\n",
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcjuJswpCMl7",
        "outputId": "7339dfeb-c0f7-4a4b-8748-b4cdd0df31d7"
      },
      "id": "XcjuJswpCMl7",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'bsc-thesis'...\n",
            "remote: Enumerating objects: 1110, done.\u001b[K\n",
            "remote: Counting objects: 100% (250/250), done.\u001b[K\n",
            "remote: Compressing objects: 100% (177/177), done.\u001b[K\n",
            "remote: Total 1110 (delta 160), reused 123 (delta 73), pack-reused 860 (from 2)\u001b[K\n",
            "Receiving objects: 100% (1110/1110), 40.21 MiB | 16.39 MiB/s, done.\n",
            "Resolving deltas: 100% (644/644), done.\n",
            "Filtering content: 100% (33/33), 1.75 GiB | 65.51 MiB/s, done.\n",
            "/content/bsc-thesis/src\n",
            "\u001b[0m\u001b[01;34mbacktesting\u001b[0m/  \u001b[01;34mdata\u001b[0m/      main.ipynb  \u001b[01;34mmodels\u001b[0m/         \u001b[01;34mutils\u001b[0m/\n",
            "\u001b[01;34mconfig\u001b[0m/       \u001b[01;34mexternal\u001b[0m/  main.py     \u001b[01;34mpreprocessing\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.26.3 # necessary for bug fix\n",
        "!pip install peft==0.10.0\n",
        "!pip install pykalman\n",
        "!pip install ta\n",
        "!pip install scikit-optimize\n",
        "\n",
        "## specific packages for time moe\n",
        "# need a different version of accelerate because of bug \"ImportError: cannot import name 'clear_device_cache' from 'accelerate.utils.memory'\"\n",
        "!pip install -U accelerate==0.32.0 # standard google colab version is 1.6.0 (apr 1, 2025), but for stability, we use time moe's 0.28.0 (mar 12, 2024)\n",
        "!pip install transformers==4.40.1 # standard google colab version is 4.51.3, but time moe repo requirements mention/prefer 4.40.1 for stability\n",
        "!pip install datasets==2.18.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBVsFvOmCS6Q",
        "outputId": "0056e3d3-a5af-45f6-a81d-4884cf905214"
      },
      "id": "VBVsFvOmCS6Q",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy==1.26.3 in /usr/local/lib/python3.11/dist-packages (1.26.3)\n",
            "Collecting peft==0.10.0\n",
            "  Using cached peft-0.10.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from peft==0.10.0) (1.26.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from peft==0.10.0) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft==0.10.0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from peft==0.10.0) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from peft==0.10.0) (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from peft==0.10.0) (4.52.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from peft==0.10.0) (4.67.1)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from peft==0.10.0) (1.7.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from peft==0.10.0) (0.5.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.11/dist-packages (from peft==0.10.0) (0.32.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.17.0->peft==0.10.0) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.17.0->peft==0.10.0) (2025.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.17.0->peft==0.10.0) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.17.0->peft==0.10.0) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.17.0->peft==0.10.0) (1.1.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.10.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.10.0) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.13.0->peft==0.10.0)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.13.0->peft==0.10.0)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.13.0->peft==0.10.0)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.13.0->peft==0.10.0)\n",
            "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.13.0->peft==0.10.0)\n",
            "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.13.0->peft==0.10.0)\n",
            "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.13.0->peft==0.10.0)\n",
            "  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.13.0->peft==0.10.0)\n",
            "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.13.0->peft==0.10.0)\n",
            "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.10.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.10.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.10.0) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.13.0->peft==0.10.0)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.10.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.10.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft==0.10.0) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->peft==0.10.0) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->peft==0.10.0) (0.21.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.0->peft==0.10.0) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.10.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.10.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.10.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.10.0) (2025.4.26)\n",
            "Using cached peft-0.10.0-py3-none-any.whl (199 kB)\n",
            "Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, peft\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: peft\n",
            "    Found existing installation: peft 0.15.2\n",
            "    Uninstalling peft-0.15.2:\n",
            "      Successfully uninstalled peft-0.15.2\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 peft-0.10.0\n",
            "Collecting pykalman\n",
            "  Using cached pykalman-0.10.1-py2.py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: numpy<3 in /usr/local/lib/python3.11/dist-packages (from pykalman) (1.26.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from pykalman) (24.2)\n",
            "Collecting scikit-base<0.13.0 (from pykalman)\n",
            "  Using cached scikit_base-0.12.3-py3-none-any.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: scipy<2.0.0 in /usr/local/lib/python3.11/dist-packages (from pykalman) (1.15.3)\n",
            "Using cached pykalman-0.10.1-py2.py3-none-any.whl (248 kB)\n",
            "Downloading scikit_base-0.12.3-py3-none-any.whl (145 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.5/145.5 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scikit-base, pykalman\n",
            "Successfully installed pykalman-0.10.1 scikit-base-0.12.3\n",
            "Collecting ta\n",
            "  Downloading ta-0.11.0.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from ta) (1.26.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from ta) (2.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->ta) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->ta) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->ta) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->ta) (1.17.0)\n",
            "Building wheels for collected packages: ta\n",
            "  Building wheel for ta (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ta: filename=ta-0.11.0-py3-none-any.whl size=29412 sha256=17a09a8210713696111e3046ea306bb2a852361468dfd39f700755addd3a449e\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/d7/29/7781cc5eb9a3659d032d7d15bdd0f49d07d2b24fec29f44bc4\n",
            "Successfully built ta\n",
            "Installing collected packages: ta\n",
            "Successfully installed ta-0.11.0\n",
            "Collecting scikit-optimize\n",
            "  Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.5.1)\n",
            "Collecting pyaml>=16.9 (from scikit-optimize)\n",
            "  Downloading pyaml-25.5.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.26.3)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.15.3)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.6.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (24.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.0->scikit-optimize) (3.6.0)\n",
            "Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl (107 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.8/107.8 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyaml-25.5.0-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-25.5.0 scikit-optimize-0.10.2\n",
            "Collecting accelerate==0.32.0\n",
            "  Downloading accelerate-0.32.0-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.32.0) (1.26.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.32.0) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate==0.32.0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate==0.32.0) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.32.0) (2.6.0+cu124)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from accelerate==0.32.0) (0.32.4)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.32.0) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.32.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.32.0) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.32.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.32.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.32.0) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.32.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.32.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.32.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.32.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.32.0) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.32.0) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.32.0) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.32.0) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.32.0) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.32.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.32.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.32.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.32.0) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.32.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.32.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate==0.32.0) (1.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->accelerate==0.32.0) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->accelerate==0.32.0) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->accelerate==0.32.0) (1.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.32.0) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->accelerate==0.32.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->accelerate==0.32.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->accelerate==0.32.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->accelerate==0.32.0) (2025.4.26)\n",
            "Downloading accelerate-0.32.0-py3-none-any.whl (314 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.0/314.0 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: accelerate\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 1.7.0\n",
            "    Uninstalling accelerate-1.7.0:\n",
            "      Successfully uninstalled accelerate-1.7.0\n",
            "Successfully installed accelerate-0.32.0\n",
            "Collecting transformers==4.40.1\n",
            "  Downloading transformers-4.40.1-py3-none-any.whl.metadata (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.0/138.0 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.40.1) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.11/dist-packages (from transformers==4.40.1) (0.32.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.40.1) (1.26.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.40.1) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.40.1) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.40.1) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.40.1) (2.32.3)\n",
            "Collecting tokenizers<0.20,>=0.19 (from transformers==4.40.1)\n",
            "  Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.40.1) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.40.1) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.40.1) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.40.1) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.40.1) (1.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.40.1) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.40.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.40.1) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.40.1) (2025.4.26)\n",
            "Downloading transformers-4.40.1-py3-none-any.whl (9.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m133.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m120.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.1\n",
            "    Uninstalling tokenizers-0.21.1:\n",
            "      Successfully uninstalled tokenizers-0.21.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.52.4\n",
            "    Uninstalling transformers-4.52.4:\n",
            "      Successfully uninstalled transformers-4.52.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sentence-transformers 4.1.0 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.40.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tokenizers-0.19.1 transformers-4.40.1\n",
            "Collecting datasets==2.18.0\n",
            "  Downloading datasets-2.18.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets==2.18.0) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets==2.18.0) (1.26.3)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets==2.18.0) (18.1.0)\n",
            "Collecting pyarrow-hotfix (from datasets==2.18.0)\n",
            "  Downloading pyarrow_hotfix-0.7-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets==2.18.0) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets==2.18.0) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from datasets==2.18.0) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from datasets==2.18.0) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets==2.18.0) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets==2.18.0) (0.70.15)\n",
            "Collecting fsspec<=2024.2.0,>=2023.1.0 (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets==2.18.0)\n",
            "  Downloading fsspec-2024.2.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets==2.18.0) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.11/dist-packages (from datasets==2.18.0) (0.32.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets==2.18.0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets==2.18.0) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.18.0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.18.0) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.18.0) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.18.0) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.18.0) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.18.0) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.18.0) (1.20.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.19.4->datasets==2.18.0) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.19.4->datasets==2.18.0) (1.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets==2.18.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets==2.18.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets==2.18.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets==2.18.0) (2025.4.26)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.18.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.18.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.18.0) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==2.18.0) (1.17.0)\n",
            "Downloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.2.0-py3-none-any.whl (170 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.9/170.9 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow_hotfix-0.7-py3-none-any.whl (7.9 kB)\n",
            "Installing collected packages: pyarrow-hotfix, fsspec, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 2.14.4\n",
            "    Uninstalling datasets-2.14.4:\n",
            "      Successfully uninstalled datasets-2.14.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.2.0 which is incompatible.\n",
            "sentence-transformers 4.1.0 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.40.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.18.0 fsspec-2024.2.0 pyarrow-hotfix-0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# bunch of the initialization code #\n",
        "\n",
        "### RESULTS IMPORTS ###\n",
        "# Module imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from typing import Optional, Callable, Dict, Any\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from matplotlib import pyplot as plt\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import AdamW\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm.auto import tqdm # note: using tqdm.auto usually automatically chooses the right import based on whether you're in CLI, notebook or somewhere else\n",
        "import torch.nn as nn\n",
        "import itertools\n",
        "from pykalman import KalmanFilter\n",
        "import ast\n",
        "import re\n",
        "from tabulate import tabulate\n",
        "from datetime import datetime\n",
        "\n",
        "# Custom Imports\n",
        "from models.statistical_models import kalman_filter_average, kalman_filter_regression\n",
        "from models.transformer_model import TimeSeriesTransformerv1, get_cosine_schedule_with_warmup_and_min_lr\n",
        "from preprocessing.cointegration import find_cointegrated_pairs\n",
        "from preprocessing.data_preprocessing import filter_pairs_data\n",
        "from preprocessing.technical_indicators import combine_pairs_data\n",
        "from preprocessing.filters import step_1_filter_remove_nans, step_2_filter_liquidity\n",
        "from backtesting.trading_strategy import trade, get_gt_yoy_returns_test_dev\n",
        "from backtesting.utils import calculate_return_uncertainty\n",
        "from utils.visualization import plot_return_uncertainty, plot_comparison\n",
        "from utils.helpers import _get_train_dev_frac\n",
        "\n",
        "# important for time moe\n",
        "import wandb\n",
        "wandb.login()\n",
        "\n",
        "## workflow imports\n",
        "from models.statistical_models import execute_kalman_workflow\n",
        "from models.transformer_model import execute_transformer_workflow\n",
        "from models.time_moe_model import execute_timemoe_workflow\n",
        "\n",
        "## specific caching imports (should be changed in case you want to gather data live)\n",
        "from data.scraper import load_cached_etf_tickers\n",
        "from data.data_collection_cache import gather_data_cached, _get_filename, gather_pairs_data_cached, gather_data_cached_using_truncate\n",
        "\n",
        "# Any other changes to be made throughout the entire notebook\n",
        "plt.style.use('seaborn-v0_8')\n",
        "\n",
        "inspect_func = False\n",
        "if inspect_func:\n",
        "  import inspect\n",
        "  print(inspect.getsource(trade)) # in this case, check whether the new trade function  is imported\n",
        "### RESULTS IMPORTS ###\n",
        "\n",
        "\n",
        "### HYPERPARAM OPTIMIZATION IMPORTS ###\n",
        "## data gathering imports\n",
        "from utils.helpers import _get_train_dev_frac\n",
        "from preprocessing.filters import step_1_filter_remove_nans, step_2_filter_liquidity\n",
        "from preprocessing.cointegration import find_cointegrated_pairs\n",
        "from preprocessing.data_preprocessing import filter_pairs_data\n",
        "from preprocessing.technical_indicators import combine_pairs_data\n",
        "## specific caching imports (should be changed in case you want to gather data live)\n",
        "from data.scraper import load_cached_etf_tickers\n",
        "from data.data_collection_cache import gather_data_cached, gather_data_cached_using_truncate, gather_pairs_data_cached, save_pairs_data_filtered\n",
        "\n",
        "## workflow imports\n",
        "from models.statistical_models import execute_kalman_workflow\n",
        "\n",
        "## optimize-specific imports\n",
        "from skopt import gp_minimize\n",
        "from skopt.space import Real\n",
        "from skopt.utils import use_named_args\n",
        "import numpy as np\n",
        "from typing import Callable, Any, List, Dict, Tuple\n",
        "import time\n",
        "import random\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "\n",
        "from utils.helpers import return_score\n",
        "from utils.visualization import results_to_latex\n",
        "from utils.optimization import bayesian_optimize_workflow\n",
        "### HYPERPARAM OPTIMIZATION IMPORTS ###"
      ],
      "metadata": {
        "id": "cLbgcEYvOQ7d"
      },
      "id": "cLbgcEYvOQ7d",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HHaEtOLZSCT-"
      },
      "id": "HHaEtOLZSCT-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Optimization"
      ],
      "metadata": {
        "id": "UVKSebsVNA_g"
      },
      "id": "UVKSebsVNA_g"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Kalman Filter"
      ],
      "metadata": {
        "id": "ZLrmV3q8NEdu"
      },
      "id": "ZLrmV3q8NEdu"
    },
    {
      "cell_type": "code",
      "source": [
        "search_space_kalman = [ # 'name' is used directly as a kwarg\n",
        "    Real(1e-5, 0.1, name='delta', prior='log-uniform'),\n",
        "    Real(0.5, 4, name='obs_cov_reg', prior='log-uniform'),\n",
        "    Real(0.001, 0.1, name='trans_cov_avg', prior='log-uniform'),\n",
        "    Real(0.1, 10, name='obs_cov_avg', prior='log-uniform')\n",
        "]\n",
        "SEED = 3178749\n",
        "\n",
        "# call func\n",
        "res_kalman = bayesian_optimize_workflow(\n",
        "    execute_workflow_fn=execute_kalman_workflow,\n",
        "    top_pair_count=10,\n",
        "    start_year=2008,\n",
        "    min_end_year=2016,\n",
        "    max_end_year=2021,\n",
        "    search_space=search_space_kalman,\n",
        "    n_calls=30,\n",
        "    seed=SEED,\n",
        "    verbose=True\n",
        ")\n",
        "param_names = [dim.name for dim in search_space_kalman]\n",
        "best_params = {k: res_kalman.x[i] for i, k in enumerate(param_names)}\n",
        "best_mean_mse = res_kalman.fun"
      ],
      "metadata": {
        "id": "3kttGwWjOBY-"
      },
      "id": "3kttGwWjOBY-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformer"
      ],
      "metadata": {
        "id": "vvMOFJt-NF-x"
      },
      "id": "vvMOFJt-NF-x"
    },
    {
      "cell_type": "code",
      "source": [
        "search_space_transformer = [ # 'name' is used directly as a kwarg\n",
        "    ...\n",
        "]\n",
        "SEED = 3178749\n",
        "\n",
        "# call func\n",
        "res_transformer = bayesian_optimize_workflow(\n",
        "    execute_workflow_fn=execute_transformer_workflow,\n",
        "    top_pair_count=10,\n",
        "    start_year=2008,\n",
        "    min_end_year=2016,\n",
        "    max_end_year=2021,\n",
        "    search_space=search_space_transformer,\n",
        "    n_calls=30,\n",
        "    seed=SEED,\n",
        "    verbose=True\n",
        ")\n",
        "param_names = [dim.name for dim in search_space_transformer]\n",
        "best_params = {k: res_transformer.x[i] for i, k in enumerate(param_names)}\n",
        "best_mean_mse = res_transformer.fun"
      ],
      "metadata": {
        "id": "VdByjLpuOELN"
      },
      "id": "VdByjLpuOELN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Time-MoE"
      ],
      "metadata": {
        "id": "PRCwzKNZNHCn"
      },
      "id": "PRCwzKNZNHCn"
    },
    {
      "cell_type": "code",
      "source": [
        "search_space_timemoe = [ # 'name' is used directly as a kwarg\n",
        "    ...\n",
        "]\n",
        "SEED = 3178749\n",
        "\n",
        "# call func\n",
        "res_timemoe = bayesian_optimize_workflow(\n",
        "    execute_workflow_fn=execute_timemoe_workflow,\n",
        "    top_pair_count=10,\n",
        "    start_year=2008,\n",
        "    min_end_year=2016,\n",
        "    max_end_year=2021,\n",
        "    search_space=search_space_timemoe,\n",
        "    n_calls=30,\n",
        "    seed=SEED,\n",
        "    verbose=True\n",
        ")\n",
        "param_names = [dim.name for dim in search_space_timemoe]\n",
        "best_params = {k: res_timemoe.x[i] for i, k in enumerate(param_names)}\n",
        "best_mean_mse = res_timemoe.fun"
      ],
      "metadata": {
        "id": "jJH6vXOOOJPY"
      },
      "id": "jJH6vXOOOJPY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Results"
      ],
      "metadata": {
        "id": "M4mUb7cqNCc-"
      },
      "id": "M4mUb7cqNCc-"
    },
    {
      "cell_type": "code",
      "source": [
        "### Unchanged variables ###\n",
        "verbose = True\n",
        "return_datasets = True\n",
        "### Unchanged variables ###"
      ],
      "metadata": {
        "id": "IjCS6tjBc4ZQ"
      },
      "id": "IjCS6tjBc4ZQ",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Kalman Filter"
      ],
      "metadata": {
        "id": "QaGpDNhfNIZb"
      },
      "id": "QaGpDNhfNIZb"
    },
    {
      "cell_type": "code",
      "source": [
        "# Hard code hyperparameters based on results above\n",
        "hyperparam_kwargs = dict(\n",
        "    delta=1e-3,\n",
        "    obs_cov_reg= 2.,\n",
        "    trans_cov_avg= 0.01,\n",
        "    obs_cov_avg= 1.\n",
        ")\n",
        "\n",
        "### Year-specific data ###\n",
        "startDateStr = '2008-01-01'\n",
        "end_year = 2022\n",
        "endDateStr = f'{end_year}-12-31'\n",
        "startDateStrTest = f'{end_year}-01-01'\n",
        "endDateStrTest = f'{end_year}-12-31'\n",
        "train_frac, dev_frac = _get_train_dev_frac(startDateStr, endDateStr, startDateStrTest, endDateStrTest)\n",
        "\n",
        "instrumentIdsNASDAQandNYSE = load_cached_etf_tickers()\n",
        "data = gather_data_cached_using_truncate(startDateStr, endDateStr, instrumentIdsNASDAQandNYSE, cache_dir='../src/data/cache')\n",
        "data_close_filtered_1, data_open_filtered_1, data_high_filtered_1, data_low_filtered_1, data_vol_filtered_1, data_original_format_filtered_1 = step_1_filter_remove_nans(data['close'], data['open'], data['high'], data['low'], data['vol'], data)\n",
        "data_close_filtered_2, data_open_filtered_2, data_high_filtered_2, data_low_filtered_2, data_vol_filtered_2, data_original_format_filtered_2 = step_2_filter_liquidity(data_close_filtered_1, data_open_filtered_1, data_high_filtered_1, data_low_filtered_1, data_vol_filtered_1, data_original_format_filtered_1)\n",
        "\n",
        "pairs_data_filtered = gather_pairs_data_cached(startDateStr, endDateStr, instrumentIdsNASDAQandNYSE, cache_dir='../src/data/cache')\n",
        "if pairs_data_filtered is None:\n",
        "  scores, pvalues, pairs = find_cointegrated_pairs(data_original_format_filtered_2)\n",
        "  pairs_data = {key:value[1]  for (key, value) in pairs.items()}\n",
        "  pairs_data = sorted(pairs_data.items(), key=lambda x: x[1])\n",
        "  pairs_data_filtered = filter_pairs_data(pairs_data) # filter based on cointegration in such a way that we can simply pick the highest pair of stocks in the list.\n",
        "  save_pairs_data_filtered(pairs_data_filtered, startDateStr, endDateStr, instrumentIdsNASDAQandNYSE, cache_dir='../src/data/cache')\n",
        "### Year-specific data ###\n",
        "\n",
        "### OPTIONAL: define worfklow here for debugging ###\n",
        "### OPTIONAL: define worfklow here for debugging ###\n",
        "\n",
        "# Gather results for 2022\n",
        "results_kalman_2022 = []\n",
        "all_outputs_kalman_2022 = []\n",
        "num_results = min(len(pairs_data_filtered), 3)\n",
        "for i in tqdm(range(num_results), desc = \"Gathering [...]\"):\n",
        "    ticker_a, ticker_b = pairs_data_filtered[i][0][0], pairs_data_filtered[i][0][1]\n",
        "    pair_tup_str_current = f\"({ticker_a},{ticker_b})\"\n",
        "    pairs_timeseries_df = combine_pairs_data(data_close_filtered_2, data_open_filtered_2, data_high_filtered_2, data_low_filtered_2, data_vol_filtered_2, ticker_a, ticker_b)\n",
        "    output_returns = get_gt_yoy_returns_test_dev(pairs_timeseries_df, dev_frac, train_frac, look_back=20)\n",
        "    gt_yoy, gt_yoy_for_dev_dataset = output_returns['gt_yoy_test'], output_returns['gt_yoy_dev']\n",
        "    output_model = execute_kalman_workflow(pairs_timeseries_df, verbose=verbose, pair_tup_str=pair_tup_str_current, train_frac=train_frac, dev_frac=dev_frac, return_datasets=return_datasets, **hyperparam_kwargs)\n",
        "    # print(output_model\n",
        "    yoy_str = f\"{output_model['yoy_mean'] * 100:.2f}% +- {output_model['yoy_std'] * 100:.2f}%\"\n",
        "    returns_score = return_score(output_model['yoy_mean'], gt_yoy)\n",
        "    cointegration_score = pairs_data_filtered[i][1]\n",
        "    results_kalman_2022.append((pair_tup_str_current, cointegration_score, output_model['val_mse'], output_model['test_mse'], yoy_str, gt_yoy, returns_score)) # (pair, cointegration_score, val, test, yoy_str, gt_yoy, returns_score)\n",
        "    all_outputs_kalman_2022.append(output_model)"
      ],
      "metadata": {
        "id": "yUt4qE-1NTuL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 596,
          "referenced_widgets": [
            "b044d020651543cebfbbe8af2770ee84",
            "cefcb2b345b641d38eb2d8b2b5b77458",
            "7c914fabff29434791aac92eae978ae3",
            "8bfc48ce2f1045dc82edfae11c5e4d19",
            "b822c5b148f04905acef7a10c35e8c8f",
            "32b407381eb746cebcd9ae3811c166dd",
            "780d3526e82b4136b733de178e370c3f",
            "22a229c29a884b36b32f21817552172f",
            "bd8c0821be8148d88f8fad9c8567076d",
            "3ca606a7c0d6481f9482bf20b46c7ac7",
            "570b580077b649a58e4cd2d9ff0088d3"
          ]
        },
        "outputId": "785eddb5-9cc3-4a19-948d-7518297762a9"
      },
      "id": "yUt4qE-1NTuL",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Gathering [...]:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b044d020651543cebfbbe8af2770ee84"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Split sizes — train: 3274, dev: 250, test: 252\n",
            "\n",
            "Validation MSE: 5.146117432637957\n",
            "Test MSE: 218.3085229192672\n",
            "YOY Returns: 6.73%\n",
            "YOY Std: +- 1.39%\n",
            "GT Yoy: 0.67%\n",
            "Plot filepath parent dir: data/results\n",
            "pair_tup_str: (PFF,EMB)\n",
            "  \n",
            "Split sizes — train: 3274, dev: 250, test: 252\n",
            "\n",
            "Validation MSE: 2.0033080974832034\n",
            "Test MSE: 294.60973362310034\n",
            "YOY Returns: 8.65%\n",
            "YOY Std: +- 1.97%\n",
            "GT Yoy: 0.42%\n",
            "Plot filepath parent dir: data/results\n",
            "pair_tup_str: (IFGL,EMB)\n",
            "  \n",
            "Split sizes — train: 3274, dev: 250, test: 252\n",
            "\n",
            "Validation MSE: 68.425164735916\n",
            "Test MSE: 32.8565597426136\n",
            "YOY Returns: 1.97%\n",
            "YOY Std: +- 0.41%\n",
            "GT Yoy: 0.83%\n",
            "Plot filepath parent dir: data/results\n",
            "pair_tup_str: (IGSB,BND)\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  # test_s1_shortened=test_s1,\n",
        "  # test_s2_shortened=test_s2,\n",
        "  # forecast_test_shortened_series=forecast_test_series,\n",
        "  # gt_test_shortened_series=gt_test_series\n",
        "for i, output in enumerate(all_outputs_kalman_2022):\n",
        "    gt_test_series, forecast_test_series = output['gt_test_shortened_series'], output['forecast_test_shortened_series']\n",
        "    plot_comparison(gt_test_series, forecast_test_series, gt_test_series.index, verbose=True)\n",
        "    plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwYXONjNUH89",
        "outputId": "701351b5-35fb-4318-97d1-a14ba246ecc6"
      },
      "id": "GwYXONjNUH89",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved plot to data_begindate_enddate_hash_groundtruth_comparison.png\n",
            "Saved plot to data_begindate_enddate_hash_groundtruth_comparison.png\n",
            "Saved plot to data_begindate_enddate_hash_groundtruth_comparison.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(results_to_latex(results_kalman_2022))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Eyl6iZmet__",
        "outputId": "9c745717-720c-413e-a843-f05b111b5d10"
      },
      "id": "1Eyl6iZmet__",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\\begin{table}[h]\n",
            "\\centering\n",
            "\\small\n",
            "\\resizebox{\\textwidth}{!}{\n",
            "\\begin{tabular}{lcccccc}\n",
            "\\toprule\n",
            "Pair & Cointegration Score & val MSE & test MSE & YoY Returns (std) & \\makecell{Theoretical Return\\\\Under Perfect\\\\Information} & Return Score \\\\\n",
            "\\midrule\n",
            "1. (PFF,EMB) & $5.58\\times 10^{-4}$ & 5.14612 & 218.30852 & $6.73\\% \\pm 1.39\\%$ & 0.61\\% & 1.06 \\\\\n",
            "2. (IFGL,EMB) & $1.40\\times 10^{-3}$ & 2.00331 & 294.60973 & $8.65\\% \\pm 1.97\\%$ & 0.43\\% & 1.08 \\\\\n",
            "3. (IGSB,BND) & $1.89\\times 10^{-3}$ & 68.42516 & 32.85656 & $1.97\\% \\pm 0.41\\%$ & 0.88\\% & 1.01 \\\\\n",
            "\\bottomrule\n",
            "\\end{tabular}\n",
            "}\n",
            "\\caption{Model performance and return statistics for all tested pairs.}\n",
            "\\end{table}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformer"
      ],
      "metadata": {
        "id": "K-8VlP2BNJVZ"
      },
      "id": "K-8VlP2BNJVZ"
    },
    {
      "cell_type": "code",
      "source": [
        "# Hard code hyperparameters based on results above\n",
        "hyperparam_kwargs = dict(\n",
        "  ## optimized hyperparams: architecture ##\n",
        "  d_model= 256,\n",
        "  nhead= 8,\n",
        "  num_layers= 4,\n",
        "  dropout = 0.1,\n",
        "  ## optimized hyperparams: architecture ##\n",
        "  ## optimized hyperparams: learning algorithm ##\n",
        "  learning_rate = 1e-4,\n",
        "  min_learning_rate = 5e-5,\n",
        "  warmup_ratio = 0.0,\n",
        "  weight_decay = 0.1,\n",
        "  batch_size= 64,\n",
        "  adam_beta1 = 0.9,\n",
        "  adam_beta2 = 0.95,\n",
        "  adam_epsilon = 1e-8\n",
        "  ## optimized hyperparams: learning algorithm ##\n",
        ")\n",
        "\n",
        "### Year-specific data ###\n",
        "startDateStr = '2008-01-01'\n",
        "end_year = 2022\n",
        "endDateStr = f'{end_year}-12-31'\n",
        "startDateStrTest = f'{end_year}-01-01'\n",
        "endDateStrTest = f'{end_year}-12-31'\n",
        "train_frac, dev_frac = _get_train_dev_frac(startDateStr, endDateStr, startDateStrTest, endDateStrTest)\n",
        "\n",
        "instrumentIdsNASDAQandNYSE = load_cached_etf_tickers()\n",
        "data = gather_data_cached_using_truncate(startDateStr, endDateStr, instrumentIdsNASDAQandNYSE, cache_dir='../src/data/cache')\n",
        "data_close_filtered_1, data_open_filtered_1, data_high_filtered_1, data_low_filtered_1, data_vol_filtered_1, data_original_format_filtered_1 = step_1_filter_remove_nans(data['close'], data['open'], data['high'], data['low'], data['vol'], data)\n",
        "data_close_filtered_2, data_open_filtered_2, data_high_filtered_2, data_low_filtered_2, data_vol_filtered_2, data_original_format_filtered_2 = step_2_filter_liquidity(data_close_filtered_1, data_open_filtered_1, data_high_filtered_1, data_low_filtered_1, data_vol_filtered_1, data_original_format_filtered_1)\n",
        "\n",
        "pairs_data_filtered = gather_pairs_data_cached(startDateStr, endDateStr, instrumentIdsNASDAQandNYSE, cache_dir='../src/data/cache')\n",
        "if pairs_data_filtered is None:\n",
        "  scores, pvalues, pairs = find_cointegrated_pairs(data_original_format_filtered_2)\n",
        "  pairs_data = {key:value[1]  for (key, value) in pairs.items()}\n",
        "  pairs_data = sorted(pairs_data.items(), key=lambda x: x[1])\n",
        "  pairs_data_filtered = filter_pairs_data(pairs_data) # filter based on cointegration in such a way that we can simply pick the highest pair of stocks in the list.\n",
        "  save_pairs_data_filtered(pairs_data_filtered, startDateStr, endDateStr, instrumentIdsNASDAQandNYSE, cache_dir='../src/data/cache')\n",
        "### Year-specific data ###\n",
        "\n",
        "### OPTIONAL: define worfklow here for debugging ###\n",
        "\n",
        "### OPTIONAL: define worfklow here for debugging ###\n",
        "\n",
        "# Gather results for 2022\n",
        "results_transformer_2022 = []\n",
        "all_outputs_transformer_2022 = []\n",
        "num_results = min(len(pairs_data_filtered), 10)\n",
        "for i in tqdm(range(num_results), desc = \"Gathering [...]\"):\n",
        "    ticker_a, ticker_b = pairs_data_filtered[i][0][0], pairs_data_filtered[i][0][1]\n",
        "    pair_tup_str_current = f\"({ticker_a},{ticker_b})\"\n",
        "    pairs_timeseries_df = combine_pairs_data(data_close_filtered_2, data_open_filtered_2, data_high_filtered_2, data_low_filtered_2, data_vol_filtered_2, ticker_a, ticker_b)\n",
        "    output_returns = get_gt_yoy_returns_test_dev(pairs_timeseries_df, dev_frac, train_frac, look_back=20)\n",
        "    gt_yoy, gt_yoy_for_dev_dataset = output_returns['gt_yoy_test'], output_returns['gt_yoy_dev']\n",
        "    output_model = execute_transformer_workflow(pairs_timeseries_df, verbose=verbose, pair_tup_str=pair_tup_str_current, train_frac=train_frac, dev_frac=dev_frac, return_datasets=return_datasets, epochs=10, **hyperparam_kwargs)\n",
        "    # print(output_model\n",
        "    yoy_str = f\"{output_model['yoy_mean'] * 100:.2f}% +- {output_model['yoy_std'] * 100:.2f}%\"\n",
        "    returns_score = return_score(output_model['yoy_mean'], gt_yoy)\n",
        "    cointegration_score = pairs_data_filtered[i][1]\n",
        "    results_transformer_2022.append((pair_tup_str_current, cointegration_score, output_model['val_mse'], output_model['test_mse'], yoy_str, gt_yoy, returns_score)) # (pair, cointegration_score, val, test, yoy_str, gt_yoy, returns_score)\n",
        "    all_outputs_transformer_2022.append(output_model)"
      ],
      "metadata": {
        "id": "Slysw0LBNlol",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "61120530a5da4213b4a9ec714349968a",
            "aecc9de2eaff4b25a1c1d44923abfb99",
            "094ab489160240a9856301372ecef6d4",
            "f2844756e3c843bfb35b21c3f8dfeaa2",
            "3725095c6b934fd695224b5df5a5b3cb",
            "36f9a1e664f746bd878fb03d53bc1583",
            "9f7cad4dcaef4e32a2b18169baf06603",
            "351249f1bbcd4b91844b1c4f2e6fff41",
            "ec32d9d60b6747d8a6c2050098d54665",
            "9095f96896404e90ac1a6c49a3e771ff",
            "3c3f1ce801cb426386bc8cc776c4ff30"
          ]
        },
        "outputId": "894bb360-1f62-4698-aa09-0acca0405bbd"
      },
      "id": "Slysw0LBNlol",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Gathering [...]:   0%|          | 0/10 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "61120530a5da4213b4a9ec714349968a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Split sizes — train: 3274, dev: 250, test: 252\n",
            "Epoch 010 | train MSE 0.026590 | val MSE 0.007395\n",
            "\n",
            "Validation MSE: 0.11768183165195598\n",
            "Test MSE: 0.07826846136668489\n",
            "YOY Returns: 0.77%\n",
            "YOY Std: +- 0.04%\n",
            "GT Yoy: 0.61%\n",
            "Plot filepath parent dir: data/results\n",
            "pair_tup_str: (PFF,EMB)\n",
            "  \n",
            "Using device: cuda\n",
            "Split sizes — train: 3274, dev: 250, test: 252\n",
            "Epoch 010 | train MSE 0.020455 | val MSE 0.004559\n",
            "\n",
            "Validation MSE: 0.10854966875197346\n",
            "Test MSE: 0.06757213082911231\n",
            "YOY Returns: 0.36%\n",
            "YOY Std: +- 0.01%\n",
            "GT Yoy: 0.43%\n",
            "Plot filepath parent dir: data/results\n",
            "pair_tup_str: (IFGL,EMB)\n",
            "  \n",
            "Using device: cuda\n",
            "Split sizes — train: 3274, dev: 250, test: 252\n",
            "Epoch 010 | train MSE 0.027080 | val MSE 0.013550\n",
            "\n",
            "Validation MSE: 0.11568501815932074\n",
            "Test MSE: 0.29119278540273247\n",
            "YOY Returns: 0.78%\n",
            "YOY Std: +- 0.03%\n",
            "GT Yoy: 0.88%\n",
            "Plot filepath parent dir: data/results\n",
            "pair_tup_str: (IGSB,BND)\n",
            "  \n",
            "Using device: cuda\n",
            "Split sizes — train: 3274, dev: 250, test: 252\n",
            "Epoch 010 | train MSE 0.024030 | val MSE 0.009397\n",
            "\n",
            "Validation MSE: 0.06550696690117595\n",
            "Test MSE: 0.04797103994271785\n",
            "YOY Returns: 1.39%\n",
            "YOY Std: +- 0.05%\n",
            "GT Yoy: 1.30%\n",
            "Plot filepath parent dir: data/results\n",
            "pair_tup_str: (USIG,IEI)\n",
            "  \n",
            "Using device: cuda\n",
            "Split sizes — train: 3274, dev: 250, test: 252\n",
            "Epoch 010 | train MSE 0.014433 | val MSE 0.071496\n",
            "\n",
            "Validation MSE: 1.424956302571987\n",
            "Test MSE: 5.909401624706703\n",
            "YOY Returns: -100.00%\n",
            "YOY Std: +- 0.00%\n",
            "GT Yoy: -100.00%\n",
            "Plot filepath parent dir: data/results\n",
            "pair_tup_str: (IGF,DVY)\n",
            "  \n",
            "Using device: cuda\n",
            "Split sizes — train: 3274, dev: 250, test: 252\n",
            "Epoch 010 | train MSE 0.020680 | val MSE 0.007630\n",
            "\n",
            "Validation MSE: 0.02913094027345031\n",
            "Test MSE: 0.1252247086219749\n",
            "YOY Returns: 0.15%\n",
            "YOY Std: +- 0.02%\n",
            "GT Yoy: 0.27%\n",
            "Plot filepath parent dir: data/results\n",
            "pair_tup_str: (DVY,PEY)\n",
            "  \n",
            "Using device: cuda\n",
            "Split sizes — train: 3274, dev: 250, test: 252\n",
            "Epoch 010 | train MSE 0.020358 | val MSE 0.008514\n",
            "\n",
            "Validation MSE: 0.1269456651373504\n",
            "Test MSE: 0.034846506484620586\n",
            "YOY Returns: 1.23%\n",
            "YOY Std: +- 0.02%\n",
            "GT Yoy: 1.15%\n",
            "Plot filepath parent dir: data/results\n",
            "pair_tup_str: (IGIB,IEI)\n",
            "  \n",
            "Using device: cuda\n",
            "Split sizes — train: 3274, dev: 250, test: 252\n",
            "Epoch 010 | train MSE 0.012671 | val MSE 0.292150\n",
            "\n",
            "Validation MSE: 1.4807613793034982\n",
            "Test MSE: 2.3085217457610923\n",
            "YOY Returns: -100.00%\n",
            "YOY Std: +- 0.00%\n",
            "GT Yoy: -100.00%\n",
            "Plot filepath parent dir: data/results\n",
            "pair_tup_str: (IFGL,SOXX)\n",
            "  \n",
            "Using device: cuda\n",
            "Split sizes — train: 3274, dev: 250, test: 252\n",
            "Epoch 010 | train MSE 0.011057 | val MSE 0.306455\n",
            "\n",
            "Validation MSE: 1.5444529628671753\n",
            "Test MSE: 2.6861519666083185\n",
            "YOY Returns: -100.00%\n",
            "YOY Std: +- 0.00%\n",
            "GT Yoy: -100.00%\n",
            "Plot filepath parent dir: data/results\n",
            "pair_tup_str: (IFGL,SMH)\n",
            "  \n",
            "Using device: cuda\n",
            "Split sizes — train: 3274, dev: 250, test: 252\n",
            "Epoch 010 | train MSE 0.011838 | val MSE 0.254725\n",
            "\n",
            "Validation MSE: 1.6803216935033891\n",
            "Test MSE: 3.0655211186954707\n",
            "YOY Returns: -5.93%\n",
            "YOY Std: +- 32.76%\n",
            "GT Yoy: 3.70%\n",
            "Plot filepath parent dir: data/results\n",
            "pair_tup_str: (IFGL,PHO)\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, output in enumerate(all_outputs_transformer_2022):\n",
        "    gt_test_series, forecast_test_series = output['gt_test_shortened_series'], output['forecast_test_shortened_series']\n",
        "    plot_comparison(gt_test_series, forecast_test_series, gt_test_series.index, verbose=True, filename_base=f\"all_outputs_transformer_2022_{i}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKa8N78glswr",
        "outputId": "1cc9fa65-bd69-4ed7-ed47-c6a7b67fcca9"
      },
      "id": "OKa8N78glswr",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved plot to all_outputs_transformer_2022_0_groundtruth_comparison.png\n",
            "Saved plot to all_outputs_transformer_2022_1_groundtruth_comparison.png\n",
            "Saved plot to all_outputs_transformer_2022_2_groundtruth_comparison.png\n",
            "Saved plot to all_outputs_transformer_2022_3_groundtruth_comparison.png\n",
            "Saved plot to all_outputs_transformer_2022_4_groundtruth_comparison.png\n",
            "Saved plot to all_outputs_transformer_2022_5_groundtruth_comparison.png\n",
            "Saved plot to all_outputs_transformer_2022_6_groundtruth_comparison.png\n",
            "Saved plot to all_outputs_transformer_2022_7_groundtruth_comparison.png\n",
            "Saved plot to all_outputs_transformer_2022_8_groundtruth_comparison.png\n",
            "Saved plot to all_outputs_transformer_2022_9_groundtruth_comparison.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Time-MoE"
      ],
      "metadata": {
        "id": "O23--vU4NKL6"
      },
      "id": "O23--vU4NKL6"
    },
    {
      "cell_type": "code",
      "source": [
        "# custom imports\n",
        "from external.time_moe_repo.training_wrapper import train_time_moe\n",
        "from backtesting.trading_strategy import get_gt_yoy_returns_test_dev\n",
        "from backtesting.utils import calculate_return_uncertainty\n",
        "\n",
        "## semi-custom\n",
        "from external.time_moe_repo.time_moe.models.modeling_time_moe import TimeMoeForPrediction\n",
        "\n",
        "from transformers import AutoModelForCausalLM, AutoConfig\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "\n",
        "\n",
        "# Hard code hyperparameters based on results above\n",
        "hyperparam_kwargs = dict(\n",
        "  ## optimized hyperparams: learning algorithm ##\n",
        "  learning_rate=1e-4,\n",
        "  min_learning_rate=5e-5,\n",
        "  warmup_ratio=0.0,\n",
        "  weight_decay=0.1,\n",
        "  global_batch_size=64, # (just the batch size) other option would be micro_batch_size, which sets batch size per device\n",
        "  adam_beta1=0.9,\n",
        "  adam_beta2=0.95,\n",
        "  adam_epsilon=1e-8,\n",
        "  ## optimized hyperparams: learning algorithm ##\n",
        ")\n",
        "\n",
        "### Year-specific data ###\n",
        "startDateStr = '2008-01-01'\n",
        "end_year = 2022\n",
        "endDateStr = f'{end_year}-12-31'\n",
        "startDateStrTest = f'{end_year}-01-01'\n",
        "endDateStrTest = f'{end_year}-12-31'\n",
        "train_frac, dev_frac = _get_train_dev_frac(startDateStr, endDateStr, startDateStrTest, endDateStrTest)\n",
        "\n",
        "instrumentIdsNASDAQandNYSE = load_cached_etf_tickers()\n",
        "data = gather_data_cached_using_truncate(startDateStr, endDateStr, instrumentIdsNASDAQandNYSE, cache_dir='../src/data/cache')\n",
        "data_close_filtered_1, data_open_filtered_1, data_high_filtered_1, data_low_filtered_1, data_vol_filtered_1, data_original_format_filtered_1 = step_1_filter_remove_nans(data['close'], data['open'], data['high'], data['low'], data['vol'], data)\n",
        "data_close_filtered_2, data_open_filtered_2, data_high_filtered_2, data_low_filtered_2, data_vol_filtered_2, data_original_format_filtered_2 = step_2_filter_liquidity(data_close_filtered_1, data_open_filtered_1, data_high_filtered_1, data_low_filtered_1, data_vol_filtered_1, data_original_format_filtered_1)\n",
        "\n",
        "pairs_data_filtered = gather_pairs_data_cached(startDateStr, endDateStr, instrumentIdsNASDAQandNYSE, cache_dir='../src/data/cache')\n",
        "if pairs_data_filtered is None:\n",
        "  scores, pvalues, pairs = find_cointegrated_pairs(data_original_format_filtered_2)\n",
        "  pairs_data = {key:value[1]  for (key, value) in pairs.items()}\n",
        "  pairs_data = sorted(pairs_data.items(), key=lambda x: x[1])\n",
        "  pairs_data_filtered = filter_pairs_data(pairs_data) # filter based on cointegration in such a way that we can simply pick the highest pair of stocks in the list.\n",
        "  save_pairs_data_filtered(pairs_data_filtered, startDateStr, endDateStr, instrumentIdsNASDAQandNYSE, cache_dir='../src/data/cache')\n",
        "### Year-specific data ###\n",
        "\n",
        "### OPTIONAL: define worfklow here for debugging ###\n",
        "\n",
        "def execute_timemoe_workflow(\n",
        "  pairs_timeseries: pd.DataFrame,\n",
        "  target_col: str = \"Spread_Close\",\n",
        "  col_s1: str = \"S1_close\",\n",
        "  col_s2: str = \"S2_close\",\n",
        "  train_frac: float = 0.90,\n",
        "  dev_frac: float = 0.05,   # remaining part is test\n",
        "  seed: int = 3178749, # for reproducibility, my student number\n",
        "  look_back: int = 20,\n",
        "  yearly_trading_days: int = 252,\n",
        "  ## optimized hyperparams ##\n",
        "  learning_rate=1e-4,\n",
        "  min_learning_rate=5e-5,\n",
        "  warmup_ratio=0.0,\n",
        "  weight_decay=0.1,\n",
        "  global_batch_size=64, # (just the batch size) other option would be micro_batch_size, which sets batch size per device\n",
        "  adam_beta1=0.9,\n",
        "  adam_beta2=0.95,\n",
        "  adam_epsilon=1e-8,\n",
        "  ## optimized hyperparams\n",
        "  return_datasets: bool = False,\n",
        "  batch_size: int = 8, # TODO: go over which batch size should be used where! (training vs test inference)\n",
        "  verbose: bool = True,\n",
        "  load_finetuned = True,\n",
        "  result_parent_dir: str = \"data/results\",\n",
        "  filename_base: str = \"data_begindate_enddate_hash.pkl\",\n",
        "  pair_tup_str: str = \"(?,?)\" # Used for showing which tuple was used in plots, example: \"(QQQ, SPY)\"\n",
        "):\n",
        "  # Set seeds\n",
        "  torch.manual_seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  random.seed(seed)\n",
        "\n",
        "  # For GPU (if used)\n",
        "  if torch.cuda.is_available():\n",
        "      torch.cuda.manual_seed(seed)\n",
        "      torch.cuda.manual_seed_all(seed)\n",
        "      torch.backends.cudnn.deterministic = True\n",
        "      torch.backends.cudnn.benchmark = False  # Might slow down, but ensures determinism\n",
        "\n",
        "  if not target_col in pairs_timeseries.columns:\n",
        "    raise KeyError(f\"pairs_timeseries must contain {target_col}\")\n",
        "\n",
        "  total_len = len(pairs_timeseries)\n",
        "  train_size = int(total_len * train_frac)\n",
        "  dev_size   = int(total_len * dev_frac)\n",
        "  test_size  = total_len - train_size - dev_size # not used, but for clarity\n",
        "\n",
        "  pairs_timeseries_univariate = pairs_timeseries[target_col]\n",
        "\n",
        "  train_univariate = pairs_timeseries_univariate[:train_size]\n",
        "  dev_univariate = pairs_timeseries_univariate[train_size:train_size+dev_size] # aka validation\n",
        "  test_univariate = pairs_timeseries_univariate[train_size+dev_size:]\n",
        "\n",
        "  train_multivariate = pairs_timeseries.iloc[:train_size]\n",
        "  dev_multivariate = pairs_timeseries.iloc[train_size:train_size+dev_size]\n",
        "  test_multivariate = pairs_timeseries.iloc[train_size+dev_size:]\n",
        "\n",
        "  if verbose:\n",
        "      print(f\"Split sizes — train: {len(train_univariate)}, dev: {len(dev_univariate)}, test: {len(test_univariate)}\")\n",
        "\n",
        "  DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "  if verbose:\n",
        "    print(f\"Using device: {DEVICE}\")\n",
        "\n",
        "  def create_sequences(series, mean=None, std=None):\n",
        "      # series: pd.Series\n",
        "      X_raw = torch.tensor(series.values, dtype=torch.float32) # note: using .values loses index\n",
        "      if mean is None:\n",
        "        # only compute mean if not given\n",
        "        mean = torch.tensor(np.array(series.mean()), dtype=torch.float32)\n",
        "      if std is None:\n",
        "        std = torch.tensor(np.array(series.std()), dtype=torch.float32)\n",
        "      X_scaled = (X_raw - mean) / (std + 1e-8)\n",
        "      return X_raw, X_scaled, mean, std\n",
        "\n",
        "  def create_sequences_rolling(series, look_back, mean=None, std=None):\n",
        "      X = []\n",
        "      y = []\n",
        "      for i in range(len(series) - look_back):\n",
        "          seq = series.iloc[i:i+look_back].values\n",
        "          target = series.iloc[i+look_back]\n",
        "          X.append(seq)\n",
        "          y.append(target)\n",
        "\n",
        "      X = torch.tensor(X, dtype=torch.float32)\n",
        "      y = torch.tensor(np.array(y), dtype=torch.float32)\n",
        "\n",
        "      # z-score normalization\n",
        "      if mean is None:\n",
        "        mean = torch.tensor(np.array(series.mean()), dtype=torch.float32)\n",
        "      if std is None:\n",
        "        std = torch.tensor(np.array(series.std()), dtype=torch.float32)\n",
        "      X_scaled = (X - mean) / (std + 1e-8)\n",
        "      # For y, broadcast mean/std to match shape\n",
        "      y_scaled = (y - mean) / (std + 1e-8)\n",
        "      return X, X_scaled, y, y_scaled, mean, std # rolling X (torch tensor), rolling X (torch tensor), torch series, scaled torch series, float, float\n",
        "\n",
        "  train_raw, train_scaled, train_mean, train_std = create_sequences(train_univariate)\n",
        "  dev_raw, dev_scaled, _, _ = create_sequences(dev_univariate, train_mean, train_std)\n",
        "  test_raw, test_scaled, _, _ = create_sequences(test_univariate, train_mean, train_std)\n",
        "\n",
        "  ## use rolling sequences not for training, but still for inferencing dev and test ##\n",
        "  trainX_raw, trainX_scaled, trainY_raw, trainY_scaled, train_mean, train_std = create_sequences_rolling(train_univariate, look_back)\n",
        "  devX_raw_rolling, devX_scaled_rolling, devY_raw_rolling, devY_scaled_rolling, _, _ = create_sequences_rolling(dev_univariate, look_back, train_mean, train_std)\n",
        "  testX_raw_rolling, testX_scaled_rolling, testY_raw_rolling, testY_scaled_rolling, _, _ = create_sequences_rolling(test_univariate, look_back, train_mean, train_std) # Note: dev_mean and test_mean may never be used; preventing data leakage\n",
        "\n",
        "  dev_ds_rolling = TensorDataset(devX_scaled_rolling, devY_scaled_rolling) # goal of TensorDataset class: loading and processing dataset lazily\n",
        "  test_ds_rolling = TensorDataset(testX_scaled_rolling, testY_scaled_rolling)\n",
        "\n",
        "  dev_loader_rolling = DataLoader(dev_ds_rolling, batch_size=batch_size, shuffle=False)\n",
        "  test_loader_rolling = DataLoader(test_ds_rolling, batch_size=batch_size, shuffle=False)\n",
        "  ## use rolling sequences not for training, but still for inferencing dev and test ##\n",
        "\n",
        "  if load_finetuned:\n",
        "    ## Training (only train in the case where we actually also want to load finetuned :D )\n",
        "    # save contents of trainX_scaled to jsonl using _get_filename {\"sequence\": [1.7994326779272853, 2.554412431241829,\n",
        "    filename_jsonl = filename_base.replace(\".pkl\", \".jsonl\")\n",
        "    filepath_parent = os.path.join(\"data\", \"datasets\")\n",
        "    os.makedirs(filepath_parent, exist_ok=True)\n",
        "    filepath_jsonl = os.path.join(filepath_parent, filename_jsonl)\n",
        "    with open(filepath_jsonl, \"w\") as f: # Train scaled (improves results according to paper, and empirical tests have also shown this)\n",
        "        json_line = json.dumps({\"sequence\": train_scaled.tolist()})\n",
        "        f.write(json_line + \"\\n\")\n",
        "\n",
        "    train_time_moe(\n",
        "        data_path=filepath_jsonl,\n",
        "        dataloader_num_workers=2,\n",
        "        ## hyperparams ##\n",
        "        learning_rate=learning_rate,\n",
        "        min_learning_rate=min_learning_rate,\n",
        "        warmup_ratio=warmup_ratio,\n",
        "        weight_decay=weight_decay,\n",
        "        global_batch_size=global_batch_size, # (just the batch size) other option would be micro_batch_size, which sets batch size per device\n",
        "        adam_beta1=adam_beta1,\n",
        "        adam_beta2=adam_beta2,\n",
        "        adam_epsilon=adam_epsilon\n",
        "        ## hyperparams ##\n",
        "    ) # after this, model is saved to logs/time_moe as model.safetensors (400+ MB)\n",
        "    model_dir = \"logs/time_moe\"\n",
        "    config = AutoConfig.from_pretrained(model_dir, trust_remote_code=True)\n",
        "    model = TimeMoeForPrediction.from_pretrained(model_dir, config=config, torch_dtype=torch.float32)\n",
        "    model.eval()\n",
        "  else:\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        'Maple728/TimeMoE-50M',\n",
        "        trust_remote_code=True,\n",
        "    )\n",
        "\n",
        "  prediction_length = 1\n",
        "\n",
        "  # forecast in batches from dev dataset\n",
        "  all_predictions = []\n",
        "  for i, batch in enumerate(test_loader_rolling):\n",
        "    inputs = batch[0] # is devX_scaled, for now [1] will return error, later [1] will return devY_scaled :D\n",
        "\n",
        "    # yvals = batch[1]\n",
        "    # means = batch[2]\n",
        "    # stds = batch[3]\n",
        "\n",
        "    output = model.generate(inputs, max_new_tokens=prediction_length)  # shape is [batch_size, look_back + prediction_length]\n",
        "    normed_predictions = output[:, -prediction_length:]\n",
        "\n",
        "    # from returned test_mean and test_std, slice the appropriate slices from the series\n",
        "    input_size_current = inputs.size()\n",
        "    batch_size_current = input_size_current[0]\n",
        "\n",
        "    preds = normed_predictions * train_std + train_mean\n",
        "    all_predictions.append(preds)\n",
        "\n",
        "  # Concatenate all predictions\n",
        "  predictions = torch.cat(all_predictions, dim=0)\n",
        "  predictions = predictions.squeeze(-1)\n",
        "  predictions = predictions.detach().numpy()\n",
        "\n",
        "  # Also get dev/val predictions\n",
        "  dev_predictions = []\n",
        "  for i, batch in enumerate(dev_loader_rolling):\n",
        "    inputs = batch[0]\n",
        "\n",
        "    output = model.generate(inputs, max_new_tokens=prediction_length)  # shape is [batch_size, look_back + prediction_length]\n",
        "    normed_predictions = output[:, -prediction_length:]\n",
        "    input_size_current = inputs.size()\n",
        "    batch_size_current = input_size_current[0]\n",
        "\n",
        "    preds = normed_predictions * train_std + train_mean\n",
        "    dev_predictions.append(preds)\n",
        "  dev_predictions = torch.cat(dev_predictions, dim=0)\n",
        "  dev_predictions = dev_predictions.squeeze(-1)\n",
        "  dev_predictions = dev_predictions.detach().numpy()\n",
        "\n",
        "  ## Trading\n",
        "  test_s1_shortened = test_multivariate[col_s1].iloc[look_back:]\n",
        "  test_s2_shortened = test_multivariate[col_s2].iloc[look_back:] # use multivariate versions, so we can still access cols like 'S1_close' and 'S2_close'\n",
        "  test_index_shortened = test_multivariate.index[look_back:] # officially doesn't really matter whether to use `test_multivariate` or `test`, but do it like this for consistency\n",
        "  forecast_test_shortened_series = pd.Series(predictions, index=test_index_shortened)\n",
        "  gt_test_shortened_series = pd.Series(test_raw.numpy()[look_back:], index=test_index_shortened)\n",
        "\n",
        "  output = get_gt_yoy_returns_test_dev(pairs_timeseries, dev_frac, train_frac, look_back=20, yearly_trading_days=yearly_trading_days)\n",
        "  gt_yoy, gt_yoy_for_dev_dataset = output['gt_yoy_test'], output['gt_yoy_dev']\n",
        "\n",
        "  ## Trading: Mean YoY\n",
        "  min_position = 2.00\n",
        "  max_position = 4.00\n",
        "  min_clearing = 0.30\n",
        "  max_clearing = 0.70\n",
        "  position_thresholds = np.linspace(min_position, max_position, num=10)\n",
        "  clearing_thresholds = np.linspace(min_clearing, max_clearing, num=10)\n",
        "  yoy_mean, yoy_std = calculate_return_uncertainty(test_s1_shortened, test_s2_shortened, forecast_test_shortened_series, position_thresholds=position_thresholds, clearing_thresholds=clearing_thresholds)\n",
        "\n",
        "  if load_finetuned:\n",
        "    current_result_dir = filename_base.replace(\".pkl\", \"_timemoe\")\n",
        "  else:\n",
        "    current_result_dir = filename_base.replace(\".pkl\", \"_timemoe_only_pretrained\")\n",
        "  result_dir = os.path.join(result_parent_dir, current_result_dir)\n",
        "  if not os.path.exists(result_dir):\n",
        "      os.makedirs(result_dir)\n",
        "\n",
        "  dev_mse = mean_squared_error(dev_raw.numpy()[look_back:], dev_predictions)\n",
        "  test_mse = mean_squared_error(test_raw.numpy()[look_back:], predictions)\n",
        "  dev_variance = dev_raw.numpy()[look_back:].var()\n",
        "  dev_nmse = dev_mse / dev_variance if dev_variance != 0 else float('inf')\n",
        "  test_variance = test_raw.numpy()[look_back:].var()\n",
        "  test_nmse = test_mse / test_variance if test_variance != 0 else float('inf')\n",
        "\n",
        "  output: Dict[str, Any] = dict(\n",
        "      val_mse=dev_nmse,\n",
        "      test_mse=test_nmse,\n",
        "      yoy_mean=yoy_mean,\n",
        "      yoy_std=yoy_std,\n",
        "      gt_yoy=gt_yoy,\n",
        "      result_parent_dir=result_parent_dir,\n",
        "  )\n",
        "\n",
        "  results_str = f\"\"\"\n",
        "Validation MSE: {output['val_mse']}\n",
        "Test MSE: {output['test_mse']}\n",
        "YOY Returns: {output['yoy_mean'] * 100:.2f}%\n",
        "YOY Std: +- {output['yoy_std'] * 100:.2f}%\n",
        "GT Yoy: {output['gt_yoy'] * 100:.2f}%\n",
        "Plot filepath parent dir: {output['result_parent_dir']}\n",
        "pair_tup_str: {pair_tup_str}\n",
        "  \"\"\"\n",
        "\n",
        "  with open(os.path.join(result_dir, \"results.txt\"), \"w\") as f:\n",
        "      f.write(results_str)\n",
        "  if verbose:\n",
        "    print(results_str)\n",
        "  if return_datasets:\n",
        "      output.update(\n",
        "          dict(\n",
        "            test_s1_shortened=test_s1_shortened,\n",
        "            test_s2_shortened=test_s2_shortened,\n",
        "            forecast_test_shortened_series=forecast_test_shortened_series,\n",
        "            gt_test_shortened_series=gt_test_shortened_series\n",
        "          )\n",
        "      )\n",
        "  return output\n",
        "\n",
        "### OPTIONAL: define worfklow here for debugging ###\n",
        "\n",
        "# Gather results for 2022\n",
        "results_timemoe_2022 = []\n",
        "all_outputs_timemoe_2022 = []\n",
        "num_results = min(len(pairs_data_filtered), 10)\n",
        "for i in tqdm(range(num_results), desc = \"Gathering [...]\"):\n",
        "    ticker_a, ticker_b = pairs_data_filtered[i][0][0], pairs_data_filtered[i][0][1]\n",
        "    pair_tup_str_current = f\"({ticker_a},{ticker_b})\"\n",
        "    pairs_timeseries_df = combine_pairs_data(data_close_filtered_2, data_open_filtered_2, data_high_filtered_2, data_low_filtered_2, data_vol_filtered_2, ticker_a, ticker_b)\n",
        "    output_returns = get_gt_yoy_returns_test_dev(pairs_timeseries_df, dev_frac, train_frac, look_back=20)\n",
        "    gt_yoy, gt_yoy_for_dev_dataset = output_returns['gt_yoy_test'], output_returns['gt_yoy_dev']\n",
        "    output_model = execute_timemoe_workflow(pairs_timeseries_df, verbose=verbose, pair_tup_str=pair_tup_str_current, train_frac=train_frac, dev_frac=dev_frac, return_datasets=return_datasets, **hyperparam_kwargs)\n",
        "    # print(output_model\n",
        "    yoy_str = f\"{output_model['yoy_mean'] * 100:.2f}% +- {output_model['yoy_std'] * 100:.2f}%\"\n",
        "    returns_score = return_score(output_model['yoy_mean'], gt_yoy)\n",
        "    cointegration_score = pairs_data_filtered[i][1]\n",
        "    results_timemoe_2022.append((pair_tup_str_current, cointegration_score, output_model['val_mse'], output_model['test_mse'], yoy_str, gt_yoy, returns_score)) # (pair, cointegration_score, val, test, yoy_str, gt_yoy, returns_score)\n",
        "    all_outputs_timemoe_2022.append(output_model)\n"
      ],
      "metadata": {
        "id": "7fAed6iSN6kS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "bd7b57f4ee5f46e693a902ea3d2519fb",
            "ee36e7c9f4b8488d8a3136b5cb5fece8",
            "56098caacd52433c9cb4f702a395a06f",
            "961b6f4aadb241db90cebf3d45fbe6f8",
            "125c4513236a414eb367dd3f8ace472c",
            "4e6bac86cead4d98a953a3a27c14ac4d",
            "6e6bae71a66e43a3b4b9591f8947d2fa",
            "90316febaad6407ab8ca051ed1db3910",
            "cfd2b47e4b5940ec80435f37b2897f7b",
            "fdbc78ab9e8b4f019341c81e345ce268",
            "5aac376810094d21a6eea3cb981efda6"
          ]
        },
        "outputId": "cfaea1b1-30a3-44e7-a27e-e827fa479c12"
      },
      "id": "7fAed6iSN6kS",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Gathering [...]:   0%|          | 0/10 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bd7b57f4ee5f46e693a902ea3d2519fb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Split sizes — train: 3274, dev: 250, test: 252\n",
            "Using device: cuda\n",
            "2025-06-15 12:45:28,090 - log_util.py[pid:1779;line:48:log_in_local_rank_0] - WARNING: Flash attention import failed, switching to eager attention.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 3554.49it/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1/1 00:00, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.031800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation MSE: 0.07027827132072963\n",
            "Test MSE: 0.1614310011637293\n",
            "YOY Returns: 0.71%\n",
            "YOY Std: +- 0.16%\n",
            "GT Yoy: 0.61%\n",
            "Plot filepath parent dir: data/results\n",
            "pair_tup_str: (PFF,EMB)\n",
            "  \n",
            "Split sizes — train: 3274, dev: 250, test: 252\n",
            "Using device: cuda\n",
            "2025-06-15 12:45:39,149 - log_util.py[pid:1779;line:48:log_in_local_rank_0] - WARNING: Flash attention import failed, switching to eager attention.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 2134.51it/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1/1 00:00, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.020900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation MSE: 0.1305880266819479\n",
            "Test MSE: 0.053724216801809985\n",
            "YOY Returns: 0.39%\n",
            "YOY Std: +- 0.15%\n",
            "GT Yoy: 0.43%\n",
            "Plot filepath parent dir: data/results\n",
            "pair_tup_str: (IFGL,EMB)\n",
            "  \n",
            "Split sizes — train: 3274, dev: 250, test: 252\n",
            "Using device: cuda\n",
            "2025-06-15 12:45:50,341 - log_util.py[pid:1779;line:48:log_in_local_rank_0] - WARNING: Flash attention import failed, switching to eager attention.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 3823.43it/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1/1 00:00, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.025900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation MSE: 0.09116217081731957\n",
            "Test MSE: 0.026181393174229645\n",
            "YOY Returns: 0.85%\n",
            "YOY Std: +- 0.12%\n",
            "GT Yoy: 0.88%\n",
            "Plot filepath parent dir: data/results\n",
            "pair_tup_str: (IGSB,BND)\n",
            "  \n",
            "Split sizes — train: 3274, dev: 250, test: 252\n",
            "Using device: cuda\n",
            "2025-06-15 12:46:01,257 - log_util.py[pid:1779;line:48:log_in_local_rank_0] - WARNING: Flash attention import failed, switching to eager attention.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 1861.65it/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1/1 00:00, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.033300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation MSE: 0.08512061650040616\n",
            "Test MSE: 0.028928096590402966\n",
            "YOY Returns: 0.94%\n",
            "YOY Std: +- 0.30%\n",
            "GT Yoy: 1.30%\n",
            "Plot filepath parent dir: data/results\n",
            "pair_tup_str: (USIG,IEI)\n",
            "  \n",
            "Split sizes — train: 3274, dev: 250, test: 252\n",
            "Using device: cuda\n",
            "2025-06-15 12:46:12,415 - log_util.py[pid:1779;line:48:log_in_local_rank_0] - WARNING: Flash attention import failed, switching to eager attention.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 2449.94it/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1/1 00:00, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.013500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation MSE: 0.0955269260518189\n",
            "Test MSE: 0.21309144824649326\n",
            "YOY Returns: -100.00%\n",
            "YOY Std: +- 0.00%\n",
            "GT Yoy: -100.00%\n",
            "Plot filepath parent dir: data/results\n",
            "pair_tup_str: (IGF,DVY)\n",
            "  \n",
            "Split sizes — train: 3274, dev: 250, test: 252\n",
            "Using device: cuda\n",
            "2025-06-15 12:46:24,047 - log_util.py[pid:1779;line:48:log_in_local_rank_0] - WARNING: Flash attention import failed, switching to eager attention.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 3075.00it/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1/1 00:00, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.022400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation MSE: 0.03617782124035344\n",
            "Test MSE: 0.11958219245546113\n",
            "YOY Returns: 0.14%\n",
            "YOY Std: +- 0.11%\n",
            "GT Yoy: 0.27%\n",
            "Plot filepath parent dir: data/results\n",
            "pair_tup_str: (DVY,PEY)\n",
            "  \n",
            "Split sizes — train: 3274, dev: 250, test: 252\n",
            "Using device: cuda\n",
            "2025-06-15 12:46:34,878 - log_util.py[pid:1779;line:48:log_in_local_rank_0] - WARNING: Flash attention import failed, switching to eager attention.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 3806.08it/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1/1 00:00, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.026800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation MSE: 0.13920061462204822\n",
            "Test MSE: 0.02691696927354444\n",
            "YOY Returns: 0.75%\n",
            "YOY Std: +- 0.27%\n",
            "GT Yoy: 1.15%\n",
            "Plot filepath parent dir: data/results\n",
            "pair_tup_str: (IGIB,IEI)\n",
            "  \n",
            "Split sizes — train: 3274, dev: 250, test: 252\n",
            "Using device: cuda\n",
            "2025-06-15 12:46:45,851 - log_util.py[pid:1779;line:48:log_in_local_rank_0] - WARNING: Flash attention import failed, switching to eager attention.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 3942.02it/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1/1 00:00, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.012000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation MSE: 0.4407105413352309\n",
            "Test MSE: 0.8651953686525966\n",
            "YOY Returns: -100.00%\n",
            "YOY Std: +- 0.00%\n",
            "GT Yoy: -100.00%\n",
            "Plot filepath parent dir: data/results\n",
            "pair_tup_str: (IFGL,SOXX)\n",
            "  \n",
            "Split sizes — train: 3274, dev: 250, test: 252\n",
            "Using device: cuda\n",
            "2025-06-15 12:46:57,191 - log_util.py[pid:1779;line:48:log_in_local_rank_0] - WARNING: Flash attention import failed, switching to eager attention.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 4609.13it/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1/1 00:00, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.012000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation MSE: 0.514559532678167\n",
            "Test MSE: 1.144887339550402\n",
            "YOY Returns: -100.00%\n",
            "YOY Std: +- 0.00%\n",
            "GT Yoy: -100.00%\n",
            "Plot filepath parent dir: data/results\n",
            "pair_tup_str: (IFGL,SMH)\n",
            "  \n",
            "Split sizes — train: 3274, dev: 250, test: 252\n",
            "Using device: cuda\n",
            "2025-06-15 12:47:08,343 - log_util.py[pid:1779;line:48:log_in_local_rank_0] - WARNING: Flash attention import failed, switching to eager attention.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 1625.70it/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1/1 00:00, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.013200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation MSE: 0.42999862771412656\n",
            "Test MSE: 0.5599547784591201\n",
            "YOY Returns: -62.04%\n",
            "YOY Std: +- 52.02%\n",
            "GT Yoy: 3.70%\n",
            "Plot filepath parent dir: data/results\n",
            "pair_tup_str: (IFGL,PHO)\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, output in enumerate(all_outputs_timemoe_2022):\n",
        "    gt_test_series, forecast_test_series = output['gt_test_shortened_series'], output['forecast_test_shortened_series']\n",
        "    plot_comparison(gt_test_series, forecast_test_series, gt_test_series.index, verbose=True, filename_base=f\"all_outputs_timemoe_2022_{i}\")"
      ],
      "metadata": {
        "id": "xwHmPM-SoErh",
        "outputId": "7ba2bbf8-b530-4b74-fe91-ec3182a73c07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "xwHmPM-SoErh",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved plot to all_outputs_timemoe_2022_0_groundtruth_comparison.png\n",
            "Saved plot to all_outputs_timemoe_2022_1_groundtruth_comparison.png\n",
            "Saved plot to all_outputs_timemoe_2022_2_groundtruth_comparison.png\n",
            "Saved plot to all_outputs_timemoe_2022_3_groundtruth_comparison.png\n",
            "Saved plot to all_outputs_timemoe_2022_4_groundtruth_comparison.png\n",
            "Saved plot to all_outputs_timemoe_2022_5_groundtruth_comparison.png\n",
            "Saved plot to all_outputs_timemoe_2022_6_groundtruth_comparison.png\n",
            "Saved plot to all_outputs_timemoe_2022_7_groundtruth_comparison.png\n",
            "Saved plot to all_outputs_timemoe_2022_8_groundtruth_comparison.png\n",
            "Saved plot to all_outputs_timemoe_2022_9_groundtruth_comparison.png\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "gpuType": "L4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b044d020651543cebfbbe8af2770ee84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cefcb2b345b641d38eb2d8b2b5b77458",
              "IPY_MODEL_7c914fabff29434791aac92eae978ae3",
              "IPY_MODEL_8bfc48ce2f1045dc82edfae11c5e4d19"
            ],
            "layout": "IPY_MODEL_b822c5b148f04905acef7a10c35e8c8f"
          }
        },
        "cefcb2b345b641d38eb2d8b2b5b77458": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32b407381eb746cebcd9ae3811c166dd",
            "placeholder": "​",
            "style": "IPY_MODEL_780d3526e82b4136b733de178e370c3f",
            "value": "Gathering [...]: 100%"
          }
        },
        "7c914fabff29434791aac92eae978ae3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22a229c29a884b36b32f21817552172f",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bd8c0821be8148d88f8fad9c8567076d",
            "value": 3
          }
        },
        "8bfc48ce2f1045dc82edfae11c5e4d19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ca606a7c0d6481f9482bf20b46c7ac7",
            "placeholder": "​",
            "style": "IPY_MODEL_570b580077b649a58e4cd2d9ff0088d3",
            "value": " 3/3 [00:09&lt;00:00,  3.21s/it]"
          }
        },
        "b822c5b148f04905acef7a10c35e8c8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32b407381eb746cebcd9ae3811c166dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "780d3526e82b4136b733de178e370c3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "22a229c29a884b36b32f21817552172f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd8c0821be8148d88f8fad9c8567076d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3ca606a7c0d6481f9482bf20b46c7ac7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "570b580077b649a58e4cd2d9ff0088d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "61120530a5da4213b4a9ec714349968a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aecc9de2eaff4b25a1c1d44923abfb99",
              "IPY_MODEL_094ab489160240a9856301372ecef6d4",
              "IPY_MODEL_f2844756e3c843bfb35b21c3f8dfeaa2"
            ],
            "layout": "IPY_MODEL_3725095c6b934fd695224b5df5a5b3cb"
          }
        },
        "aecc9de2eaff4b25a1c1d44923abfb99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36f9a1e664f746bd878fb03d53bc1583",
            "placeholder": "​",
            "style": "IPY_MODEL_9f7cad4dcaef4e32a2b18169baf06603",
            "value": "Gathering [...]: 100%"
          }
        },
        "094ab489160240a9856301372ecef6d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_351249f1bbcd4b91844b1c4f2e6fff41",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ec32d9d60b6747d8a6c2050098d54665",
            "value": 10
          }
        },
        "f2844756e3c843bfb35b21c3f8dfeaa2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9095f96896404e90ac1a6c49a3e771ff",
            "placeholder": "​",
            "style": "IPY_MODEL_3c3f1ce801cb426386bc8cc776c4ff30",
            "value": " 10/10 [01:15&lt;00:00,  7.55s/it]"
          }
        },
        "3725095c6b934fd695224b5df5a5b3cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36f9a1e664f746bd878fb03d53bc1583": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f7cad4dcaef4e32a2b18169baf06603": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "351249f1bbcd4b91844b1c4f2e6fff41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec32d9d60b6747d8a6c2050098d54665": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9095f96896404e90ac1a6c49a3e771ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c3f1ce801cb426386bc8cc776c4ff30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd7b57f4ee5f46e693a902ea3d2519fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ee36e7c9f4b8488d8a3136b5cb5fece8",
              "IPY_MODEL_56098caacd52433c9cb4f702a395a06f",
              "IPY_MODEL_961b6f4aadb241db90cebf3d45fbe6f8"
            ],
            "layout": "IPY_MODEL_125c4513236a414eb367dd3f8ace472c"
          }
        },
        "ee36e7c9f4b8488d8a3136b5cb5fece8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e6bac86cead4d98a953a3a27c14ac4d",
            "placeholder": "​",
            "style": "IPY_MODEL_6e6bae71a66e43a3b4b9591f8947d2fa",
            "value": "Gathering [...]: 100%"
          }
        },
        "56098caacd52433c9cb4f702a395a06f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90316febaad6407ab8ca051ed1db3910",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cfd2b47e4b5940ec80435f37b2897f7b",
            "value": 10
          }
        },
        "961b6f4aadb241db90cebf3d45fbe6f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fdbc78ab9e8b4f019341c81e345ce268",
            "placeholder": "​",
            "style": "IPY_MODEL_5aac376810094d21a6eea3cb981efda6",
            "value": " 10/10 [01:51&lt;00:00, 11.17s/it]"
          }
        },
        "125c4513236a414eb367dd3f8ace472c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e6bac86cead4d98a953a3a27c14ac4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e6bae71a66e43a3b4b9591f8947d2fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "90316febaad6407ab8ca051ed1db3910": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfd2b47e4b5940ec80435f37b2897f7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fdbc78ab9e8b4f019341c81e345ce268": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5aac376810094d21a6eea3cb981efda6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}