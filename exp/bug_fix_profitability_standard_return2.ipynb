{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "## Set Up Notebook ##\n",
        "\n",
        "# if \"preprocessing\" folder in current folders -> cd back to original folder\n",
        "%cd /content\n",
        "import os\n",
        "if os.path.exists(\"bsc-thesis\"):\n",
        "  # if bsc-thesis folder already exists; completely remove\n",
        "  !rm -rf bsc-thesis\n",
        "# cloning repo\n",
        "branch = \"main\"\n",
        "!git clone --branch $branch https://github.com/maviddoerdijk/bsc-thesis.git\n",
        "\n",
        "# moving into project dir\n",
        "%cd bsc-thesis/src\n",
        "%ls\n",
        "\n",
        "\n",
        "## Set Up Notebook"
      ],
      "metadata": {
        "id": "fEKBP3eCotC5",
        "outputId": "fa82e557-dcd1-4a6d-843c-931eb40c1c8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "fEKBP3eCotC5",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'bsc-thesis'...\n",
            "remote: Enumerating objects: 864, done.\u001b[K\n",
            "remote: Counting objects: 100% (244/244), done.\u001b[K\n",
            "remote: Compressing objects: 100% (197/197), done.\u001b[K\n",
            "remote: Total 864 (delta 139), reused 120 (delta 47), pack-reused 620 (from 1)\u001b[K\n",
            "Receiving objects: 100% (864/864), 27.23 MiB | 19.50 MiB/s, done.\n",
            "Resolving deltas: 100% (493/493), done.\n",
            "Filtering content: 100% (32/32), 1.75 GiB | 32.01 MiB/s, done.\n",
            "/content/bsc-thesis/src\n",
            "\u001b[0m\u001b[01;34mbacktesting\u001b[0m/  \u001b[01;34mdata\u001b[0m/      main.ipynb  \u001b[01;34mmodels\u001b[0m/         \u001b[01;34mutils\u001b[0m/\n",
            "\u001b[01;34mconfig\u001b[0m/       \u001b[01;34mexternal\u001b[0m/  main.py     \u001b[01;34mpreprocessing\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Set Up Notebook ##\n",
        "\n",
        "!pip install numpy==1.26.3 # necessary for bug fix\n",
        "!pip install ta\n",
        "!pip install pykalman\n",
        "!pip install PyWavelets\n",
        "\n",
        "## Set Up Notebook"
      ],
      "metadata": {
        "id": "_cHFI4_hoyHh",
        "outputId": "49c8b477-64e4-4f7e-d861-0ced1ee8df10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "_cHFI4_hoyHh",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy==1.26.3 in /usr/local/lib/python3.11/dist-packages (1.26.3)\n",
            "Requirement already satisfied: ta in /usr/local/lib/python3.11/dist-packages (0.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from ta) (1.26.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from ta) (2.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->ta) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->ta) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->ta) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->ta) (1.17.0)\n",
            "Requirement already satisfied: pykalman in /usr/local/lib/python3.11/dist-packages (0.10.1)\n",
            "Requirement already satisfied: numpy<3 in /usr/local/lib/python3.11/dist-packages (from pykalman) (1.26.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from pykalman) (24.2)\n",
            "Requirement already satisfied: scikit-base<0.13.0 in /usr/local/lib/python3.11/dist-packages (from pykalman) (0.12.2)\n",
            "Requirement already satisfied: scipy<2.0.0 in /usr/local/lib/python3.11/dist-packages (from pykalman) (1.15.3)\n",
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.11/dist-packages (1.8.0)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from PyWavelets) (1.26.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Module imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from typing import Optional, Callable, Dict, Any\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from matplotlib import pyplot as plt\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import AdamW\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm.auto import tqdm # note: using tqdm.auto usually automatically chooses the right import based on whether you're in CLI, notebook or somewhere else\n",
        "import torch.nn as nn\n",
        "import itertools\n",
        "from pykalman import KalmanFilter\n",
        "import ast\n",
        "import re\n",
        "from tabulate import tabulate\n",
        "from datetime import datetime\n",
        "\n",
        "# Custom Imports\n",
        "from models.statistical_models import create_dataset, default_normalize, rmse_metric, acc_metric, kalman_filter_average, kalman_filter_regression, kalman_filter_regression_multivariate\n",
        "from preprocessing.cointegration import find_cointegrated_pairs\n",
        "from preprocessing.data_preprocessing import filter_pairs_data\n",
        "from preprocessing.technical_indicators import combine_pairs_data\n",
        "from preprocessing.wavelet_denoising import wav_den\n",
        "from preprocessing.filters import step_1_filter_remove_nans, step_2_filter_liquidity\n",
        "from backtesting.trading_strategy import trade, get_gt_yoy_returns_test_dev\n",
        "from backtesting.utils import calculate_return_uncertainty\n",
        "from utils.visualization import plot_return_uncertainty, plot_comparison\n",
        "from utils.helpers import _get_train_dev_frac\n",
        "\n",
        "# important for time moe\n",
        "# import wandb\n",
        "# wandb.login()\n",
        "\n",
        "## workflow imports\n",
        "from models.statistical_models import execute_kalman_workflow\n",
        "from models.transformer_model import execute_transformer_workflow\n",
        "# from models.time_moe_model import execute_timemoe_workflow\n",
        "\n",
        "## specific caching imports (should be changed in case you want to gather data live)\n",
        "from data.scraper import load_cached_etf_tickers\n",
        "from data.data_collection_cache import gather_data_cached, _get_filename, gather_pairs_data_cached, gather_data_cached_using_truncate\n",
        "\n",
        "# Any other changes to be made throughout the entire notebook\n",
        "plt.style.use('seaborn-v0_8')"
      ],
      "metadata": {
        "id": "CKij434oo-5E"
      },
      "id": "CKij434oo-5E",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "11d6ad02",
      "metadata": {
        "id": "11d6ad02"
      },
      "outputs": [],
      "source": [
        "## Gather Data ##\n",
        "\n",
        "startDateStr = '2008-01-01'\n",
        "end_year = 2024\n",
        "endDateStr = f'{end_year}-12-31'\n",
        "startDateStrTest = f'{end_year}-01-01' # possibly change to 07-01 (option 1; dev data in end_year - 1 (e.g. 2023), test data in end_year (e.g. 2024) // option 2; dev data 1st half end_year, test data 2nd half end_year)\n",
        "endDateStrTest = f'{end_year}-12-31'\n",
        "train_frac, dev_frac = _get_train_dev_frac(startDateStr, endDateStr, startDateStrTest, endDateStrTest)\n",
        "\n",
        "instrumentIdsNASDAQandNYSE = load_cached_etf_tickers()\n",
        "data = gather_data_cached_using_truncate(startDateStr, endDateStr, instrumentIdsNASDAQandNYSE, cache_dir='../src/data/cache')\n",
        "data_close_filtered_1, data_open_filtered_1, data_high_filtered_1, data_low_filtered_1, data_vol_filtered_1, data_original_format_filtered_1 = step_1_filter_remove_nans(data['close'], data['open'], data['high'], data['low'], data['vol'], data)\n",
        "data_close_filtered_2, data_open_filtered_2, data_high_filtered_2, data_low_filtered_2, data_vol_filtered_2, data_original_format_filtered_2 = step_2_filter_liquidity(data_close_filtered_1, data_open_filtered_1, data_high_filtered_1, data_low_filtered_1, data_vol_filtered_1, data_original_format_filtered_1)\n",
        "\n",
        "pairs_data_filtered = gather_pairs_data_cached(startDateStr, endDateStr, instrumentIdsNASDAQandNYSE, cache_dir='../src/data/cache')\n",
        "if pairs_data_filtered is None:\n",
        "  scores, pvalues, pairs = find_cointegrated_pairs(data_original_format_filtered_2)\n",
        "  pairs_data = {key:value[1]  for (key, value) in pairs.items()}\n",
        "  pairs_data = sorted(pairs_data.items(), key=lambda x: x[1])\n",
        "  pairs_data_filtered = filter_pairs_data(pairs_data) # filter based on cointegration in such a way that we can simply pick the highest pair of stocks in the list.\n",
        "\n",
        "\n",
        "\n",
        "## Gather Data ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "7f8e009b",
      "metadata": {
        "id": "7f8e009b",
        "outputId": "d3b26f4f-f00a-49fe-d7ac-58d66c22b767",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.020931007337921637\n",
            "-1.0\n",
            "0.0723128658560368\n",
            "0.008752546953437301\n",
            "-1.0\n",
            "-0.47037563254892034\n",
            "-1.0\n",
            "4.785235020964784\n",
            "1.9733132748176931\n",
            "-1.0\n",
            "0.0398909225689148\n",
            "-1.0\n",
            "1.2670809730464314\n",
            "8.868132561102678\n",
            "0.018237098104780358\n",
            "-1.0\n",
            "1.7432821082693417\n",
            "-1.0\n",
            "-1.0\n",
            "-0.4279133854072428\n",
            "3.695024554655274\n",
            "-1.0\n",
            "-1.0\n",
            "0.007887762782601282\n",
            "-1.0\n",
            "3.3244533226445308\n",
            "-1.0\n",
            "-1.0\n",
            "0.8412458556031881\n",
            "0.1305934402254212\n",
            "-1.0\n",
            "2.1116305362202277\n",
            "0.2550074907544648\n",
            "-1.0\n",
            "-1.0\n",
            "-0.011092336443212836\n",
            "0.2369322958942428\n",
            "0.8167691354564885\n",
            "-1.0\n",
            "0.036205107373399104\n",
            "6.320417696370613\n",
            "-1.0\n",
            "2.619843616025543\n",
            "-1.0\n",
            "0.015553846312416741\n",
            "0.11329536604554535\n",
            "-1.0\n",
            "0.024733272806903628\n",
            "14.952935571050498\n",
            "1.3322686683982803\n",
            "0.09585534661848083\n",
            "-1.0\n",
            "2.289618108407116\n",
            "5.0532437147867535\n",
            "0.027206706740262154\n",
            "1.1688299869177912\n",
            "-1.0\n",
            "0.6072773555829407\n",
            "-1.0\n",
            "-1.0\n",
            "0.7522905370306183\n",
            "0.45700529332185624\n",
            "3.5647459245111186\n",
            "-1.0\n",
            "2.4623712196740017\n",
            "-1.0\n",
            "0.48739815875685855\n",
            "1.6888194878165326\n",
            "0.44443086646939367\n",
            "0.6242071972454257\n",
            "1.0925098607365036\n",
            "4.271423928046406\n",
            "2.365630037159228\n",
            "0.7705132917330146\n",
            "0.24603389072170656\n",
            "0.31160277305628803\n",
            "3.0780587670766\n",
            "-0.42020776632511647\n",
            "-0.37061580842762454\n",
            "0.06660519312292501\n",
            "0.04857461732370649\n",
            "0.2063164714605883\n",
            "2.182988312322239\n",
            "0.6077714221425408\n",
            "0.2955613536475392\n",
            "0.17575209834321615\n",
            "-1.0\n",
            "3.194074730247025\n",
            "0.019077574621933602\n",
            "-1.0\n",
            "-1.0\n",
            "1.0294806022641518\n",
            "0.4703199097653723\n",
            "0.2053368991415514\n",
            "0.012046244331973766\n",
            "0.5219012636648983\n",
            "-0.8739974790251341\n",
            "-1.0\n",
            "-1.0\n",
            "-0.07785971276213055\n",
            "-1.0\n",
            "0.051156319487901225\n",
            "0.1578713547325643\n"
          ]
        }
      ],
      "source": [
        "# Goal: find out why so many returns show gt_yoy -15.275%\n",
        "\n",
        "verbose = False\n",
        "\n",
        "def return_score(yoy_mean, gt_yoy):\n",
        "  return round((1 + yoy_mean) / (1 + gt_yoy), 2)\n",
        "\n",
        "# output_returns = get_gt_yoy_returns_test_dev(pairs_timeseries_df, dev_frac, train_frac, look_back=20)\n",
        "# gt_yoy, gt_yoy_for_dev_dataset = output_returns['gt_yoy_test'], output_returns['gt_yoy_dev']\n",
        "\n",
        "## definition of trade func ##\n",
        "\n",
        "\n",
        "def trade(\n",
        "        S1: pd.Series,\n",
        "        S2: pd.Series,\n",
        "        spread: pd.Series, # model-predicted spread for the strategy\n",
        "        window_long: int,\n",
        "        window_short: int,\n",
        "        position_threshold: float = 1.0,\n",
        "        clearing_threshold: float = 0.5,\n",
        "        risk_fraction: float = 0.1 # could be used again\n",
        "    ):\n",
        "    if len(spread) != len(S1) or len(spread) != len(S2):\n",
        "        raise ValueError(\"Length of S1, S2, and spread must be the same\")\n",
        "    # Compute rolling mean and rolling standard deviation\n",
        "\n",
        "    ma_long = spread.rolling(window=window_long, center=False).mean()\n",
        "    ma_short = spread.rolling(window=window_short, center=False).mean()\n",
        "    std = spread.rolling(window=window_short, center=False).std()\n",
        "    zscore = (ma_long - ma_short)/std\n",
        "\n",
        "    # Calculate initial cash based on average range of S1, S2 and Spread_Close, as these also determine the size of the trades\n",
        "    s2_spread = max(S2) - min(S2)\n",
        "    s1_spread = max(S1) - min(S1)\n",
        "    spread_spread = max(spread) - min(spread)\n",
        "    avg_spread = (s2_spread + s1_spread + spread_spread) / 3\n",
        "    initial_cash = avg_spread * len(spread) # the absolute returns are correlated to the length of the spread, times the average range.\n",
        "    # overwrite initial_cash to standard value\n",
        "    initial_cash = 10000\n",
        "\n",
        "    # Simulate trading\n",
        "    # Start with no money and no positions\n",
        "    cash = initial_cash # initial cash amount, perhaps not hardcoded in the future\n",
        "    qty_s1 = 0\n",
        "    qty_s2 = 0\n",
        "    returns = [initial_cash]\n",
        "\n",
        "    for i in range(len(spread)):\n",
        "        # Sell short if the z-score is > 1\n",
        "        if zscore.iloc[i] > position_threshold:\n",
        "            # print(f\"[NEW] Step {i}: SELL SHORT, z={zscore.iloc[i]:.2f}, S1={S1.iloc[i]:.2f}, S2={S2.iloc[i]:.2f}, spread={spread.iloc[i]:.2f}, cash={cash:.2f}, qty_s1={qty_s1}, qty_s2={qty_s2}\")\n",
        "            cash += S1.iloc[i] - S2.iloc[i] * spread.iloc[i]\n",
        "            qty_s1 -= 1\n",
        "            qty_s2 += spread.iloc[i]\n",
        "        # Buy long if the z-score is < 1\n",
        "        elif zscore.iloc[i] < -position_threshold:\n",
        "            # print(f\"[NEW] Step {i}: BUY LONG, z={zscore.iloc[i]:.2f}, S1={S1.iloc[i]:.2f}, S2={S2.iloc[i]:.2f}, spread={spread.iloc[i]:.2f}, cash={cash:.2f}, qty_s1={qty_s1}, qty_s2={qty_s2}\")\n",
        "            cash -= S1.iloc[i] - S2.iloc[i] * spread.iloc[i]\n",
        "            qty_s1 += 1\n",
        "            qty_s2 -= spread.iloc[i]\n",
        "        # Clear positions if the z-score between -.5 and .5\n",
        "        elif abs(zscore.iloc[i]) < clearing_threshold:\n",
        "            # print(f\"[NEW] Step {i}: CLEAR POSITION, z={zscore.iloc[i]:.2f}, S1={S1.iloc[i]:.2f}, S2={S2.iloc[i]:.2f}, spread={spread.iloc[i]:.2f}, cash={cash:.2f}, qty_s1={qty_s1}, qty_s2={qty_s2}\")\n",
        "            cash += qty_s1 * S1.iloc[i] - S2.iloc[i] * qty_s2\n",
        "            qty_s1 = 0\n",
        "            qty_s2 = 0\n",
        "        returns.append(cash) # append the current cash value to returns\n",
        "    # If at any point returns is 0, all values after that is zero\n",
        "    zero_from_this_idx = -1\n",
        "    for i in range(len(returns)):\n",
        "        if returns[i] <= 0:\n",
        "            zero_from_this_idx = i\n",
        "            break\n",
        "    if zero_from_this_idx > -1:\n",
        "        returns[zero_from_this_idx:] = [0] * (len(returns) - zero_from_this_idx)\n",
        "\n",
        "    # Shrink returns by a factor such that returns are not inflated.\n",
        "    returns_series = pd.Series(returns)\n",
        "    alpha = 0.1  # Shrinking/stretching factor\n",
        "    returns_uninflated = returns_series.copy()\n",
        "    mask = returns_series > initial_cash\n",
        "    returns_uninflated[mask] = initial_cash + alpha * (returns_series[mask] - initial_cash)\n",
        "    returns_uninflated = returns_uninflated.tolist()\n",
        "\n",
        "    return returns_uninflated\n",
        "\n",
        "\n",
        "## definition of trade func\n",
        "\n",
        "\n",
        "\n",
        "## Preparing for trade\n",
        "for i in range(len(pairs_data_filtered)):\n",
        "  ticker_a, ticker_b = pairs_data_filtered[i][0][0], pairs_data_filtered[i][0][1]\n",
        "  pair_tup_str_current = f\"({ticker_a},{ticker_b})\"\n",
        "  pairs_timeseries_df = combine_pairs_data(data_close_filtered_2, data_open_filtered_2, data_high_filtered_2, data_low_filtered_2, data_vol_filtered_2, ticker_a, ticker_b)\n",
        "\n",
        "  burn_in = 30\n",
        "  look_back = 20\n",
        "\n",
        "  pairs_timeseries_df_burned_in = pairs_timeseries_df.iloc[burn_in:].copy()\n",
        "\n",
        "  total_len = len(pairs_timeseries_df_burned_in)\n",
        "  train_size = int(total_len * train_frac)\n",
        "  dev_size   = int(total_len * dev_frac)\n",
        "  test_size  = total_len - train_size - dev_size # not used, but for clarity\n",
        "\n",
        "  train = pairs_timeseries_df_burned_in.iloc[:train_size]\n",
        "  dev   = pairs_timeseries_df_burned_in.iloc[train_size:train_size + dev_size]\n",
        "  test  = pairs_timeseries_df_burned_in.iloc[train_size + dev_size:]\n",
        "\n",
        "\n",
        "  index_shortened = test.index[:len(test['Spread_Close'].values[look_back:])] # problem: test['S1_close'].iloc[look_back:] and testY_untr are the same.. So we should rather be using test\n",
        "  spread_gt_series = pd.Series(test['Spread_Close'].values[look_back:], index=index_shortened)\n",
        "  gt_returns_test = trade(\n",
        "      S1 = test['S1_close'].iloc[look_back:],\n",
        "      S2 = test['S2_close'].iloc[look_back:],\n",
        "      spread = spread_gt_series,\n",
        "      window_long = 30,\n",
        "      window_short = 5,\n",
        "      position_threshold = 3,\n",
        "      clearing_threshold = 0.4\n",
        "  )\n",
        "\n",
        "  ## Preparing for trade\n",
        "\n",
        "  # plt.plot(gt_returns_test)\n",
        "  gt_yoy_test = ((gt_returns_test[-1] / gt_returns_test[0])**(232 / len(gt_returns_test)) - 1) # should be -100, but is -15..\n",
        "  print(gt_yoy_test)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}