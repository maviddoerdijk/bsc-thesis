{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# if \"preprocessing\" folder in current folders -> cd back to original folder\n",
        "%cd /content\n",
        "import os\n",
        "if os.path.exists(\"bsc-thesis\"):\n",
        "  # if bsc-thesis folder already exists; completely remove\n",
        "  !rm -rf bsc-thesis\n",
        "\n",
        "# cloning repo\n",
        "branch = \"main\"\n",
        "!git clone --branch $branch https://github.com/maviddoerdijk/bsc-thesis.git\n",
        "\n",
        "# moving into project dir\n",
        "%cd bsc-thesis/src\n",
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcjuJswpCMl7",
        "outputId": "89b02bc7-1bbf-475f-e160-e5a9ed85f9c3"
      },
      "id": "XcjuJswpCMl7",
      "execution_count": 3,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'bsc-thesis'...\n",
            "remote: Enumerating objects: 1177, done.\u001b[K\n",
            "remote: Counting objects: 100% (100/100), done.\u001b[K\n",
            "remote: Compressing objects: 100% (57/57), done.\u001b[K\n",
            "remote: Total 1177 (delta 65), reused 56 (delta 43), pack-reused 1077 (from 1)\u001b[K\n",
            "Receiving objects: 100% (1177/1177), 30.71 MiB | 9.92 MiB/s, done.\n",
            "Resolving deltas: 100% (722/722), done.\n",
            "Filtering content: 100% (33/33), 1.75 GiB | 67.31 MiB/s, done.\n",
            "/content/bsc-thesis/src\n",
            "\u001b[0m\u001b[01;34mbacktesting\u001b[0m/  \u001b[01;34mdata\u001b[0m/      main.ipynb  \u001b[01;34mmodels\u001b[0m/         \u001b[01;34mutils\u001b[0m/\n",
            "\u001b[01;34mconfig\u001b[0m/       \u001b[01;34mexternal\u001b[0m/  main.py     \u001b[01;34mpreprocessing\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.26.3 # necessary for bug fix\n",
        "!pip install peft==0.10.0\n",
        "!pip install pykalman\n",
        "!pip install ta\n",
        "!pip install scikit-optimize\n",
        "\n",
        "## specific packages for time moe\n",
        "# need a different version of accelerate because of bug \"ImportError: cannot import name 'clear_device_cache' from 'accelerate.utils.memory'\"\n",
        "!pip install -U accelerate==0.32.0 # standard google colab version is 1.6.0 (apr 1, 2025), but for stability, we use time moe's 0.28.0 (mar 12, 2024)\n",
        "!pip install transformers==4.40.1 # standard google colab version is 4.51.3, but time moe repo requirements mention/prefer 4.40.1 for stability\n",
        "!pip install datasets==2.18.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBVsFvOmCS6Q",
        "outputId": "279efe99-bd40-420c-c58b-238e0e8c1141"
      },
      "id": "VBVsFvOmCS6Q",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy==1.26.3 in /usr/local/lib/python3.11/dist-packages (1.26.3)\n",
            "Collecting peft==0.10.0\n",
            "  Using cached peft-0.10.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from peft==0.10.0) (1.26.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from peft==0.10.0) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft==0.10.0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from peft==0.10.0) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from peft==0.10.0) (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from peft==0.10.0) (4.52.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from peft==0.10.0) (4.67.1)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from peft==0.10.0) (1.7.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from peft==0.10.0) (0.5.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.11/dist-packages (from peft==0.10.0) (0.32.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.17.0->peft==0.10.0) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.17.0->peft==0.10.0) (2025.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.17.0->peft==0.10.0) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.17.0->peft==0.10.0) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.17.0->peft==0.10.0) (1.1.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.10.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.10.0) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.13.0->peft==0.10.0)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.13.0->peft==0.10.0)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.13.0->peft==0.10.0)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.13.0->peft==0.10.0)\n",
            "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.13.0->peft==0.10.0)\n",
            "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.13.0->peft==0.10.0)\n",
            "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.13.0->peft==0.10.0)\n",
            "  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.13.0->peft==0.10.0)\n",
            "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.13.0->peft==0.10.0)\n",
            "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.10.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.10.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.10.0) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.13.0->peft==0.10.0)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.10.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.10.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft==0.10.0) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->peft==0.10.0) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->peft==0.10.0) (0.21.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.0->peft==0.10.0) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.10.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.10.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.10.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.10.0) (2025.4.26)\n",
            "Using cached peft-0.10.0-py3-none-any.whl (199 kB)\n",
            "Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m65.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m102.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, peft\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: peft\n",
            "    Found existing installation: peft 0.15.2\n",
            "    Uninstalling peft-0.15.2:\n",
            "      Successfully uninstalled peft-0.15.2\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 peft-0.10.0\n",
            "Collecting pykalman\n",
            "  Using cached pykalman-0.10.1-py2.py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: numpy<3 in /usr/local/lib/python3.11/dist-packages (from pykalman) (1.26.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from pykalman) (24.2)\n",
            "Collecting scikit-base<0.13.0 (from pykalman)\n",
            "  Using cached scikit_base-0.12.3-py3-none-any.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: scipy<2.0.0 in /usr/local/lib/python3.11/dist-packages (from pykalman) (1.15.3)\n",
            "Using cached pykalman-0.10.1-py2.py3-none-any.whl (248 kB)\n",
            "Downloading scikit_base-0.12.3-py3-none-any.whl (145 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.5/145.5 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scikit-base, pykalman\n",
            "Successfully installed pykalman-0.10.1 scikit-base-0.12.3\n",
            "Collecting ta\n",
            "  Downloading ta-0.11.0.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from ta) (1.26.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from ta) (2.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->ta) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->ta) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->ta) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->ta) (1.17.0)\n",
            "Building wheels for collected packages: ta\n",
            "  Building wheel for ta (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ta: filename=ta-0.11.0-py3-none-any.whl size=29412 sha256=3d0b4d0b9aad4849edb69001413ab91b4b68fe223b119e42d46d7285aa98e6e7\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/d7/29/7781cc5eb9a3659d032d7d15bdd0f49d07d2b24fec29f44bc4\n",
            "Successfully built ta\n",
            "Installing collected packages: ta\n",
            "Successfully installed ta-0.11.0\n",
            "Collecting scikit-optimize\n",
            "  Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.5.1)\n",
            "Collecting pyaml>=16.9 (from scikit-optimize)\n",
            "  Downloading pyaml-25.5.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.26.3)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.15.3)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.6.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (24.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.0->scikit-optimize) (3.6.0)\n",
            "Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl (107 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.8/107.8 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyaml-25.5.0-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-25.5.0 scikit-optimize-0.10.2\n",
            "Collecting accelerate==0.32.0\n",
            "  Downloading accelerate-0.32.0-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.32.0) (1.26.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.32.0) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate==0.32.0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate==0.32.0) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.32.0) (2.6.0+cu124)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from accelerate==0.32.0) (0.32.4)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.32.0) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.32.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.32.0) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.32.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.32.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.32.0) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.32.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.32.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.32.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.32.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.32.0) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.32.0) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.32.0) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.32.0) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.32.0) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.32.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.32.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.32.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.32.0) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.32.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.32.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate==0.32.0) (1.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->accelerate==0.32.0) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->accelerate==0.32.0) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->accelerate==0.32.0) (1.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.32.0) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->accelerate==0.32.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->accelerate==0.32.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->accelerate==0.32.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->accelerate==0.32.0) (2025.4.26)\n",
            "Downloading accelerate-0.32.0-py3-none-any.whl (314 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.0/314.0 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: accelerate\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 1.7.0\n",
            "    Uninstalling accelerate-1.7.0:\n",
            "      Successfully uninstalled accelerate-1.7.0\n",
            "Successfully installed accelerate-0.32.0\n",
            "Collecting transformers==4.40.1\n",
            "  Downloading transformers-4.40.1-py3-none-any.whl.metadata (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.0/138.0 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.40.1) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.11/dist-packages (from transformers==4.40.1) (0.32.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.40.1) (1.26.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.40.1) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.40.1) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.40.1) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.40.1) (2.32.3)\n",
            "Collecting tokenizers<0.20,>=0.19 (from transformers==4.40.1)\n",
            "  Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.40.1) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.40.1) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.40.1) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.40.1) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.40.1) (1.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.40.1) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.40.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.40.1) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.40.1) (2025.4.26)\n",
            "Downloading transformers-4.40.1-py3-none-any.whl (9.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m98.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m113.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.1\n",
            "    Uninstalling tokenizers-0.21.1:\n",
            "      Successfully uninstalled tokenizers-0.21.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.52.4\n",
            "    Uninstalling transformers-4.52.4:\n",
            "      Successfully uninstalled transformers-4.52.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sentence-transformers 4.1.0 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.40.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tokenizers-0.19.1 transformers-4.40.1\n",
            "Collecting datasets==2.18.0\n",
            "  Downloading datasets-2.18.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets==2.18.0) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets==2.18.0) (1.26.3)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets==2.18.0) (18.1.0)\n",
            "Collecting pyarrow-hotfix (from datasets==2.18.0)\n",
            "  Downloading pyarrow_hotfix-0.7-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets==2.18.0) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets==2.18.0) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from datasets==2.18.0) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from datasets==2.18.0) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets==2.18.0) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets==2.18.0) (0.70.15)\n",
            "Collecting fsspec<=2024.2.0,>=2023.1.0 (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets==2.18.0)\n",
            "  Downloading fsspec-2024.2.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets==2.18.0) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.11/dist-packages (from datasets==2.18.0) (0.32.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets==2.18.0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets==2.18.0) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.18.0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.18.0) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.18.0) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.18.0) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.18.0) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.18.0) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.18.0) (1.20.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.19.4->datasets==2.18.0) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.19.4->datasets==2.18.0) (1.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets==2.18.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets==2.18.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets==2.18.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets==2.18.0) (2025.4.26)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.18.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.18.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.18.0) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==2.18.0) (1.17.0)\n",
            "Downloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.2.0-py3-none-any.whl (170 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.9/170.9 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow_hotfix-0.7-py3-none-any.whl (7.9 kB)\n",
            "Installing collected packages: pyarrow-hotfix, fsspec, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 2.14.4\n",
            "    Uninstalling datasets-2.14.4:\n",
            "      Successfully uninstalled datasets-2.14.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.2.0 which is incompatible.\n",
            "sentence-transformers 4.1.0 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.40.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.18.0 fsspec-2024.2.0 pyarrow-hotfix-0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# bunch of the initialization code #\n",
        "\n",
        "### RESULTS IMPORTS ###\n",
        "# Module imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from typing import Optional, Callable, Dict, Any, Sequence\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from matplotlib import pyplot as plt\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import AdamW\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm.auto import tqdm # note: using tqdm.auto usually automatically chooses the right import based on whether you're in CLI, notebook or somewhere else\n",
        "import torch.nn as nn\n",
        "import itertools\n",
        "from pykalman import KalmanFilter\n",
        "import ast\n",
        "import re\n",
        "from tabulate import tabulate\n",
        "from datetime import datetime\n",
        "from transformers import AutoModelForCausalLM, AutoConfig\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Custom Imports\n",
        "from models.statistical_models import kalman_filter_average, kalman_filter_regression\n",
        "from models.transformer_model import TimeSeriesTransformerv1, get_cosine_schedule_with_warmup_and_min_lr\n",
        "from preprocessing.cointegration import find_cointegrated_pairs\n",
        "from preprocessing.data_preprocessing import filter_pairs_data\n",
        "from preprocessing.technical_indicators import combine_pairs_data\n",
        "from preprocessing.filters import step_1_filter_remove_nans, step_2_filter_liquidity\n",
        "from backtesting.trading_strategy import trade, get_gt_yoy_returns_test_dev\n",
        "from backtesting.utils import calculate_return_uncertainty\n",
        "from utils.visualization import plot_return_uncertainty, plot_comparison\n",
        "from utils.helpers import _get_train_dev_frac\n",
        "from external.time_moe_repo.training_wrapper import train_time_moe\n",
        "from backtesting.trading_strategy import get_gt_yoy_returns_test_dev\n",
        "from backtesting.utils import calculate_return_uncertainty\n",
        "\n",
        "## semi-custom\n",
        "from external.time_moe_repo.time_moe.models.modeling_time_moe import TimeMoeForPrediction\n",
        "\n",
        "# important for time moe\n",
        "import wandb\n",
        "wandb.login()\n",
        "\n",
        "## workflow imports\n",
        "from models.statistical_models import execute_kalman_workflow\n",
        "from models.transformer_model import execute_transformer_workflow\n",
        "from models.time_moe_model import execute_timemoe_workflow\n",
        "\n",
        "## specific caching imports (should be changed in case you want to gather data live)\n",
        "from data.scraper import load_cached_etf_tickers\n",
        "from data.data_collection_cache import gather_data_cached, _get_filename, gather_pairs_data_cached, gather_data_cached_using_truncate\n",
        "\n",
        "# Any other changes to be made throughout the entire notebook\n",
        "plt.style.use('seaborn-v0_8')\n",
        "\n",
        "inspect_func = False\n",
        "if inspect_func:\n",
        "  import inspect\n",
        "  print(inspect.getsource(trade)) # in this case, check whether the new trade function  is imported\n",
        "### RESULTS IMPORTS ###\n",
        "\n",
        "\n",
        "### HYPERPARAM OPTIMIZATION IMPORTS ###\n",
        "## data gathering imports\n",
        "from utils.helpers import _get_train_dev_frac\n",
        "from preprocessing.filters import step_1_filter_remove_nans, step_2_filter_liquidity\n",
        "from preprocessing.cointegration import find_cointegrated_pairs\n",
        "from preprocessing.data_preprocessing import filter_pairs_data\n",
        "from preprocessing.technical_indicators import combine_pairs_data\n",
        "## specific caching imports (should be changed in case you want to gather data live)\n",
        "from data.scraper import load_cached_etf_tickers\n",
        "from data.data_collection_cache import gather_data_cached, gather_data_cached_using_truncate, gather_pairs_data_cached, save_pairs_data_filtered\n",
        "\n",
        "## workflow imports\n",
        "from models.statistical_models import execute_kalman_workflow\n",
        "\n",
        "## optimize-specific imports\n",
        "from skopt import gp_minimize\n",
        "from skopt import plots as skplots\n",
        "from skopt.space import Real\n",
        "from skopt.utils import use_named_args\n",
        "import numpy as np\n",
        "from typing import Callable, Any, List, Dict, Tuple\n",
        "import time\n",
        "import random\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "\n",
        "from utils.helpers import return_score\n",
        "from utils.visualization import results_to_latex\n",
        "from utils.optimization import bayesian_optimize_workflow\n",
        "### HYPERPARAM OPTIMIZATION IMPORTS ###"
      ],
      "metadata": {
        "id": "cLbgcEYvOQ7d"
      },
      "id": "cLbgcEYvOQ7d",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Optimization"
      ],
      "metadata": {
        "id": "UVKSebsVNA_g"
      },
      "id": "UVKSebsVNA_g"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformer"
      ],
      "metadata": {
        "id": "vvMOFJt-NF-x"
      },
      "id": "vvMOFJt-NF-x"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Time-MoE"
      ],
      "metadata": {
        "id": "PRCwzKNZNHCn"
      },
      "id": "PRCwzKNZNHCn"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Results"
      ],
      "metadata": {
        "id": "M4mUb7cqNCc-"
      },
      "id": "M4mUb7cqNCc-"
    },
    {
      "cell_type": "code",
      "source": [
        "### Unchanged variables ###\n",
        "verbose = True\n",
        "return_datasets = True\n",
        "### Unchanged variables ###"
      ],
      "metadata": {
        "id": "IjCS6tjBc4ZQ"
      },
      "id": "IjCS6tjBc4ZQ",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformer"
      ],
      "metadata": {
        "id": "K-8VlP2BNJVZ"
      },
      "id": "K-8VlP2BNJVZ"
    },
    {
      "cell_type": "code",
      "source": [
        "# Hard code hyperparameters based on results above\n",
        "hyperparam_kwargs = {'d_model': 256, 'nhead': 8, 'num_layers': 3, 'dropout': 0.1423652841511892, 'learning_rate': 2.4360790710388177e-06, 'min_learning_rate': 8.416991137830168e-05, 'warmup_ratio': 0.01016486209190529, 'weight_decay': 0.27550315286937016, 'batch_size': 64, 'adam_beta1': 0.9595914559778183, 'adam_beta2': 0.9696258195959361, 'adam_epsilon': 5.235073338871379e-10}\n",
        "\n",
        "### Year-specific data ###\n",
        "startDateStr = '2008-01-01'\n",
        "end_year = 2023\n",
        "endDateStr = f'{end_year}-12-31'\n",
        "startDateStrTest = f'{end_year}-01-01'\n",
        "endDateStrTest = f'{end_year}-12-31'\n",
        "train_frac, dev_frac = _get_train_dev_frac(startDateStr, endDateStr, startDateStrTest, endDateStrTest)\n",
        "\n",
        "instrumentIdsNASDAQandNYSE = load_cached_etf_tickers()\n",
        "data = gather_data_cached_using_truncate(startDateStr, endDateStr, instrumentIdsNASDAQandNYSE, cache_dir='../src/data/cache')\n",
        "data_close_filtered_1, data_open_filtered_1, data_high_filtered_1, data_low_filtered_1, data_vol_filtered_1, data_original_format_filtered_1 = step_1_filter_remove_nans(data['close'], data['open'], data['high'], data['low'], data['vol'], data)\n",
        "data_close_filtered_2, data_open_filtered_2, data_high_filtered_2, data_low_filtered_2, data_vol_filtered_2, data_original_format_filtered_2 = step_2_filter_liquidity(data_close_filtered_1, data_open_filtered_1, data_high_filtered_1, data_low_filtered_1, data_vol_filtered_1, data_original_format_filtered_1)\n",
        "\n",
        "pairs_data_filtered = gather_pairs_data_cached(startDateStr, endDateStr, instrumentIdsNASDAQandNYSE, cache_dir='../src/data/cache')\n",
        "if pairs_data_filtered is None:\n",
        "  scores, pvalues, pairs = find_cointegrated_pairs(data_original_format_filtered_2)\n",
        "  pairs_data = {key:value[1]  for (key, value) in pairs.items()}\n",
        "  pairs_data = sorted(pairs_data.items(), key=lambda x: x[1])\n",
        "  pairs_data_filtered = filter_pairs_data(pairs_data) # filter based on cointegration in such a way that we can simply pick the highest pair of stocks in the list.\n",
        "  save_pairs_data_filtered(pairs_data_filtered, startDateStr, endDateStr, instrumentIdsNASDAQandNYSE, cache_dir='../src/data/cache')\n",
        "### Year-specific data ###\n",
        "\n",
        "### OPTIONAL: define worfklow here for debugging ###\n",
        "\n",
        "### OPTIONAL: define worfklow here for debugging ###\n",
        "\n",
        "# Gather results for 2023\n",
        "results_transformer_2023 = []\n",
        "all_outputs_transformer_2023 = []\n",
        "num_results = min(len(pairs_data_filtered), 10)\n",
        "for i in tqdm(range(num_results), desc = \"Gathering [...]\"):\n",
        "    ticker_a, ticker_b = pairs_data_filtered[i][0][0], pairs_data_filtered[i][0][1]\n",
        "    pair_tup_str_current = f\"({ticker_a},{ticker_b})\"\n",
        "    pairs_timeseries_df = combine_pairs_data(data_close_filtered_2, data_open_filtered_2, data_high_filtered_2, data_low_filtered_2, data_vol_filtered_2, ticker_a, ticker_b)\n",
        "    output_returns = get_gt_yoy_returns_test_dev(pairs_timeseries_df, dev_frac, train_frac, look_back=20)\n",
        "    gt_yoy, gt_yoy_for_dev_dataset = output_returns['gt_yoy_test'], output_returns['gt_yoy_dev']\n",
        "    output_model = execute_transformer_workflow(pairs_timeseries_df, verbose=verbose, pair_tup_str=pair_tup_str_current, train_frac=train_frac, dev_frac=dev_frac, return_datasets=return_datasets, epochs=300, **hyperparam_kwargs)\n",
        "    # print(output_model\n",
        "    yoy_str = f\"{output_model['yoy_mean'] * 100:.2f}% +- {output_model['yoy_std'] * 100:.2f}%\"\n",
        "    returns_score = return_score(output_model['yoy_mean'], gt_yoy)\n",
        "    cointegration_score = pairs_data_filtered[i][1]\n",
        "    results_transformer_2023.append((pair_tup_str_current, cointegration_score, output_model['val_mse'], output_model['test_mse'], yoy_str, gt_yoy, returns_score)) # (pair, cointegration_score, val, test, yoy_str, gt_yoy, returns_score)\n",
        "    all_outputs_transformer_2023.append(output_model)"
      ],
      "metadata": {
        "id": "Slysw0LBNlol",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "61285f11a1dd4fc6b68c1b092eeedc55",
            "f4a210a4e180473a8a412fc95971fe66",
            "d551dbf3fe6545e1bae2fc6613ed16b9",
            "b270c199d43a47a0aa99bc0a65a02f35",
            "28c6cfccc5bf484d8490c02a808becfe",
            "e650f394bcbd4356955e44573cd71304",
            "98bf5640cc26458f82b213f3224a414e",
            "2daa4af64c724ffaa6683981ff06b564",
            "6621540de689465a9d13fa3f12b2908c",
            "1301482167b640f2952dc0282b955e49",
            "8dae436fde6d414abfa04302db8e0520"
          ]
        },
        "outputId": "f1b5e49a-96dc-4255-b24c-e20da796cd2a"
      },
      "id": "Slysw0LBNlol",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Gathering [...]:   0%|          | 0/10 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "61285f11a1dd4fc6b68c1b092eeedc55"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Split sizes — train: 3524, dev: 250, test: 252\n",
            "Epoch 010 | train MSE 0.653356 | val MSE 0.588635\n",
            "Epoch 020 | train MSE 0.269327 | val MSE 0.070661\n",
            "Epoch 030 | train MSE 0.174512 | val MSE 0.086444\n",
            "Epoch 040 | train MSE 0.119244 | val MSE 0.066548\n",
            "Epoch 050 | train MSE 0.091540 | val MSE 0.053524\n",
            "Epoch 060 | train MSE 0.073481 | val MSE 0.045756\n",
            "Epoch 070 | train MSE 0.060940 | val MSE 0.028961\n",
            "Epoch 080 | train MSE 0.052738 | val MSE 0.022146\n",
            "Epoch 090 | train MSE 0.042446 | val MSE 0.016651\n",
            "Epoch 100 | train MSE 0.038379 | val MSE 0.014049\n",
            "Epoch 110 | train MSE 0.034105 | val MSE 0.013331\n",
            "Epoch 120 | train MSE 0.030754 | val MSE 0.012170\n",
            "Epoch 130 | train MSE 0.028123 | val MSE 0.011037\n",
            "Epoch 140 | train MSE 0.028070 | val MSE 0.010829\n",
            "Epoch 150 | train MSE 0.026371 | val MSE 0.010856\n",
            "Epoch 160 | train MSE 0.024976 | val MSE 0.010793\n",
            "Epoch 170 | train MSE 0.030340 | val MSE 0.039703\n",
            "Epoch 180 | train MSE 0.026965 | val MSE 0.045517\n",
            "Epoch 190 | train MSE 0.021543 | val MSE 0.013292\n",
            "Epoch 200 | train MSE 0.020038 | val MSE 0.015545\n",
            "Epoch 210 | train MSE 0.018677 | val MSE 0.014924\n",
            "Epoch 220 | train MSE 0.018713 | val MSE 0.010927\n",
            "Epoch 230 | train MSE 0.017585 | val MSE 0.010427\n",
            "Epoch 240 | train MSE 0.015655 | val MSE 0.020984\n",
            "Epoch 250 | train MSE 0.017116 | val MSE 0.012191\n",
            "Epoch 260 | train MSE 0.015778 | val MSE 0.011450\n",
            "Epoch 270 | train MSE 0.016384 | val MSE 0.012451\n",
            "Epoch 280 | train MSE 0.014904 | val MSE 0.016705\n",
            "Epoch 290 | train MSE 0.013639 | val MSE 0.018322\n",
            "Epoch 300 | train MSE 0.013789 | val MSE 0.012292\n",
            "\n",
            "Validation MSE: 0.06809691286868251\n",
            "Test MSE: 0.16529179945582292\n",
            "YOY Returns: 0.09%\n",
            "YOY Std: +- 0.01%\n",
            "GT Yoy: -0.06%\n",
            "Plot filepath parent dir: data/results\n",
            "pair_tup_str: (PFF,EMB)\n",
            "  \n",
            "Using device: cuda\n",
            "Split sizes — train: 3524, dev: 250, test: 252\n",
            "Epoch 010 | train MSE 0.618785 | val MSE 0.063130\n",
            "Epoch 020 | train MSE 0.202097 | val MSE 0.024650\n",
            "Epoch 030 | train MSE 0.097892 | val MSE 0.014039\n",
            "Epoch 040 | train MSE 0.058562 | val MSE 0.011170\n",
            "Epoch 050 | train MSE 0.045523 | val MSE 0.009856\n",
            "Epoch 060 | train MSE 0.033658 | val MSE 0.008117\n",
            "Epoch 070 | train MSE 0.027628 | val MSE 0.007057\n",
            "Epoch 080 | train MSE 0.025114 | val MSE 0.006762\n",
            "Epoch 090 | train MSE 0.020910 | val MSE 0.006159\n",
            "Epoch 100 | train MSE 0.020506 | val MSE 0.005101\n",
            "Epoch 110 | train MSE 0.019758 | val MSE 0.005020\n",
            "Epoch 120 | train MSE 0.017566 | val MSE 0.005234\n",
            "Epoch 130 | train MSE 0.016022 | val MSE 0.004774\n",
            "Epoch 140 | train MSE 0.016221 | val MSE 0.004711\n",
            "Epoch 150 | train MSE 0.015544 | val MSE 0.004153\n",
            "Epoch 160 | train MSE 0.014798 | val MSE 0.003921\n",
            "Epoch 170 | train MSE 0.019554 | val MSE 0.007279\n",
            "Epoch 180 | train MSE 0.019589 | val MSE 0.006596\n",
            "Epoch 190 | train MSE 0.016535 | val MSE 0.004708\n",
            "Epoch 200 | train MSE 0.016014 | val MSE 0.005582\n",
            "Epoch 210 | train MSE 0.015346 | val MSE 0.003500\n",
            "Epoch 220 | train MSE 0.017582 | val MSE 0.003364\n",
            "Epoch 230 | train MSE 0.014856 | val MSE 0.003830\n",
            "Epoch 240 | train MSE 0.014523 | val MSE 0.003550\n",
            "Epoch 250 | train MSE 0.014387 | val MSE 0.003561\n",
            "Epoch 260 | train MSE 0.015640 | val MSE 0.004819\n",
            "Epoch 270 | train MSE 0.014809 | val MSE 0.003564\n",
            "Epoch 280 | train MSE 0.013742 | val MSE 0.004011\n",
            "Epoch 290 | train MSE 0.012649 | val MSE 0.003254\n",
            "Epoch 300 | train MSE 0.013734 | val MSE 0.003433\n",
            "\n",
            "Validation MSE: 0.034791181274804316\n",
            "Test MSE: 0.09328248746010306\n",
            "YOY Returns: 0.43%\n",
            "YOY Std: +- 0.07%\n",
            "GT Yoy: 0.65%\n",
            "Plot filepath parent dir: data/results\n",
            "pair_tup_str: (IFGL,EMB)\n",
            "  \n",
            "Using device: cuda\n",
            "Split sizes — train: 3524, dev: 250, test: 252\n",
            "Epoch 010 | train MSE 0.560562 | val MSE 3.434611\n",
            "Epoch 020 | train MSE 0.073853 | val MSE 0.500192\n",
            "Epoch 030 | train MSE 0.040495 | val MSE 0.084190\n",
            "Epoch 040 | train MSE 0.028006 | val MSE 0.020832\n",
            "Epoch 050 | train MSE 0.019349 | val MSE 0.010575\n",
            "Epoch 060 | train MSE 0.015641 | val MSE 0.008462\n",
            "Epoch 070 | train MSE 0.014383 | val MSE 0.008238\n",
            "Epoch 080 | train MSE 0.013175 | val MSE 0.008655\n",
            "Epoch 090 | train MSE 0.012492 | val MSE 0.007360\n",
            "Epoch 100 | train MSE 0.011878 | val MSE 0.013029\n",
            "Epoch 110 | train MSE 0.010718 | val MSE 0.006719\n",
            "Epoch 120 | train MSE 0.009917 | val MSE 0.006429\n",
            "Epoch 130 | train MSE 0.009538 | val MSE 0.009049\n",
            "Epoch 140 | train MSE 0.008991 | val MSE 0.005328\n",
            "Epoch 150 | train MSE 0.009018 | val MSE 0.007679\n",
            "Epoch 160 | train MSE 0.008437 | val MSE 0.006112\n",
            "Epoch 170 | train MSE 0.011825 | val MSE 0.005300\n",
            "Epoch 180 | train MSE 0.009582 | val MSE 0.010046\n",
            "Epoch 190 | train MSE 0.010879 | val MSE 0.010349\n",
            "Epoch 200 | train MSE 0.010092 | val MSE 0.002971\n",
            "Epoch 210 | train MSE 0.011185 | val MSE 0.004237\n",
            "Epoch 220 | train MSE 0.010015 | val MSE 0.004063\n",
            "Epoch 230 | train MSE 0.010108 | val MSE 0.002789\n",
            "Epoch 240 | train MSE 0.008915 | val MSE 0.002814\n",
            "Epoch 250 | train MSE 0.008917 | val MSE 0.004044\n",
            "Epoch 260 | train MSE 0.009193 | val MSE 0.002812\n",
            "Epoch 270 | train MSE 0.009511 | val MSE 0.002520\n",
            "Epoch 280 | train MSE 0.008498 | val MSE 0.005980\n",
            "Epoch 290 | train MSE 0.008319 | val MSE 0.004051\n",
            "Epoch 300 | train MSE 0.008219 | val MSE 0.002705\n",
            "\n",
            "Validation MSE: 0.15913772677473056\n",
            "Test MSE: 0.08200073382357406\n",
            "YOY Returns: -100.00%\n",
            "YOY Std: +- 0.00%\n",
            "GT Yoy: -100.00%\n",
            "Plot filepath parent dir: data/results\n",
            "pair_tup_str: (IGF,DVY)\n",
            "  \n",
            "Using device: cuda\n",
            "Split sizes — train: 3524, dev: 250, test: 252\n",
            "Epoch 010 | train MSE 0.645794 | val MSE 1.219538\n",
            "Epoch 020 | train MSE 0.208571 | val MSE 0.141956\n",
            "Epoch 030 | train MSE 0.128724 | val MSE 0.083036\n",
            "Epoch 040 | train MSE 0.089710 | val MSE 0.064635\n",
            "Epoch 050 | train MSE 0.061258 | val MSE 0.053569\n",
            "Epoch 060 | train MSE 0.046540 | val MSE 0.047495\n",
            "Epoch 070 | train MSE 0.036922 | val MSE 0.046241\n",
            "Epoch 080 | train MSE 0.032543 | val MSE 0.040483\n",
            "Epoch 090 | train MSE 0.028560 | val MSE 0.036128\n",
            "Epoch 100 | train MSE 0.024687 | val MSE 0.030340\n",
            "Epoch 110 | train MSE 0.022862 | val MSE 0.028186\n",
            "Epoch 120 | train MSE 0.023105 | val MSE 0.024125\n",
            "Epoch 130 | train MSE 0.020615 | val MSE 0.022010\n",
            "Epoch 140 | train MSE 0.019637 | val MSE 0.018611\n",
            "Epoch 150 | train MSE 0.019040 | val MSE 0.018081\n",
            "Epoch 160 | train MSE 0.017566 | val MSE 0.017897\n",
            "Epoch 170 | train MSE 0.022841 | val MSE 0.052517\n",
            "Epoch 180 | train MSE 0.018255 | val MSE 0.015095\n",
            "Epoch 190 | train MSE 0.017536 | val MSE 0.014859\n",
            "Epoch 200 | train MSE 0.014842 | val MSE 0.015426\n",
            "Epoch 210 | train MSE 0.015756 | val MSE 0.014105\n",
            "Epoch 220 | train MSE 0.016789 | val MSE 0.013363\n",
            "Epoch 230 | train MSE 0.015904 | val MSE 0.022075\n",
            "Epoch 240 | train MSE 0.014101 | val MSE 0.012173\n",
            "Epoch 250 | train MSE 0.015485 | val MSE 0.018032\n",
            "Epoch 260 | train MSE 0.013909 | val MSE 0.015819\n",
            "Epoch 270 | train MSE 0.013692 | val MSE 0.016839\n",
            "Epoch 280 | train MSE 0.015346 | val MSE 0.025874\n",
            "Epoch 290 | train MSE 0.014557 | val MSE 0.034611\n",
            "Epoch 300 | train MSE 0.013376 | val MSE 0.013973\n",
            "\n",
            "Validation MSE: 0.026158747301324982\n",
            "Test MSE: 0.06271294869546776\n",
            "YOY Returns: 0.48%\n",
            "YOY Std: +- 0.03%\n",
            "GT Yoy: 0.50%\n",
            "Plot filepath parent dir: data/results\n",
            "pair_tup_str: (IGIB,IEI)\n",
            "  \n",
            "Using device: cuda\n",
            "Split sizes — train: 3524, dev: 250, test: 252\n",
            "Epoch 010 | train MSE 0.562554 | val MSE 0.296189\n",
            "Epoch 020 | train MSE 0.134907 | val MSE 0.098774\n",
            "Epoch 030 | train MSE 0.085533 | val MSE 0.084981\n",
            "Epoch 040 | train MSE 0.062778 | val MSE 0.073274\n",
            "Epoch 050 | train MSE 0.049443 | val MSE 0.065219\n",
            "Epoch 060 | train MSE 0.038407 | val MSE 0.057040\n",
            "Epoch 070 | train MSE 0.033776 | val MSE 0.050137\n",
            "Epoch 080 | train MSE 0.030117 | val MSE 0.045180\n",
            "Epoch 090 | train MSE 0.026078 | val MSE 0.040299\n",
            "Epoch 100 | train MSE 0.023459 | val MSE 0.038148\n",
            "Epoch 110 | train MSE 0.021730 | val MSE 0.033470\n",
            "Epoch 120 | train MSE 0.021019 | val MSE 0.029823\n",
            "Epoch 130 | train MSE 0.019788 | val MSE 0.028242\n",
            "Epoch 140 | train MSE 0.018244 | val MSE 0.025230\n",
            "Epoch 150 | train MSE 0.017648 | val MSE 0.023997\n",
            "Epoch 160 | train MSE 0.016505 | val MSE 0.022654\n",
            "Epoch 170 | train MSE 0.020517 | val MSE 0.019294\n",
            "Epoch 180 | train MSE 0.020018 | val MSE 0.018127\n",
            "Epoch 190 | train MSE 0.018395 | val MSE 0.018335\n",
            "Epoch 200 | train MSE 0.018812 | val MSE 0.019057\n",
            "Epoch 210 | train MSE 0.019765 | val MSE 0.021364\n",
            "Epoch 220 | train MSE 0.019193 | val MSE 0.018036\n",
            "Epoch 230 | train MSE 0.016813 | val MSE 0.016529\n",
            "Epoch 240 | train MSE 0.015746 | val MSE 0.017403\n",
            "Epoch 250 | train MSE 0.015641 | val MSE 0.020094\n",
            "Epoch 260 | train MSE 0.014835 | val MSE 0.018774\n",
            "Epoch 270 | train MSE 0.015085 | val MSE 0.018374\n",
            "Epoch 280 | train MSE 0.016136 | val MSE 0.017782\n",
            "Epoch 290 | train MSE 0.014680 | val MSE 0.018366\n",
            "Epoch 300 | train MSE 0.014548 | val MSE 0.019336\n",
            "\n",
            "Validation MSE: 0.12655765234974878\n",
            "Test MSE: 0.05569325801796802\n",
            "YOY Returns: 0.21%\n",
            "YOY Std: +- 0.01%\n",
            "GT Yoy: 0.15%\n",
            "Plot filepath parent dir: data/results\n",
            "pair_tup_str: (DVY,PEY)\n",
            "  \n",
            "Using device: cuda\n",
            "Split sizes — train: 3524, dev: 250, test: 252\n",
            "Epoch 010 | train MSE 0.728295 | val MSE 1.350922\n",
            "Epoch 020 | train MSE 0.293374 | val MSE 0.149469\n",
            "Epoch 030 | train MSE 0.162271 | val MSE 0.130502\n",
            "Epoch 040 | train MSE 0.110242 | val MSE 0.115555\n",
            "Epoch 050 | train MSE 0.079095 | val MSE 0.078168\n",
            "Epoch 060 | train MSE 0.060991 | val MSE 0.059490\n",
            "Epoch 070 | train MSE 0.048378 | val MSE 0.047833\n",
            "Epoch 080 | train MSE 0.044004 | val MSE 0.040281\n",
            "Epoch 090 | train MSE 0.036482 | val MSE 0.033931\n",
            "Epoch 100 | train MSE 0.032313 | val MSE 0.029923\n",
            "Epoch 110 | train MSE 0.028872 | val MSE 0.024980\n",
            "Epoch 120 | train MSE 0.029152 | val MSE 0.020274\n",
            "Epoch 130 | train MSE 0.025531 | val MSE 0.019894\n",
            "Epoch 140 | train MSE 0.023132 | val MSE 0.018668\n",
            "Epoch 150 | train MSE 0.022715 | val MSE 0.016813\n",
            "Epoch 160 | train MSE 0.021544 | val MSE 0.017597\n",
            "Epoch 170 | train MSE 0.026858 | val MSE 0.024782\n",
            "Epoch 180 | train MSE 0.020911 | val MSE 0.018990\n",
            "Epoch 190 | train MSE 0.019028 | val MSE 0.019584\n",
            "Epoch 200 | train MSE 0.017979 | val MSE 0.018876\n",
            "Epoch 210 | train MSE 0.017424 | val MSE 0.022700\n",
            "Epoch 220 | train MSE 0.018213 | val MSE 0.013855\n",
            "Epoch 230 | train MSE 0.016390 | val MSE 0.015747\n",
            "Epoch 240 | train MSE 0.015741 | val MSE 0.015507\n",
            "Epoch 250 | train MSE 0.016167 | val MSE 0.020423\n",
            "Epoch 260 | train MSE 0.013711 | val MSE 0.014113\n",
            "Epoch 270 | train MSE 0.014822 | val MSE 0.013959\n",
            "Epoch 280 | train MSE 0.013898 | val MSE 0.022182\n",
            "Epoch 290 | train MSE 0.015833 | val MSE 0.016693\n",
            "Epoch 300 | train MSE 0.013765 | val MSE 0.021949\n",
            "\n",
            "Validation MSE: 0.04194880870719344\n",
            "Test MSE: 0.18978364312254148\n",
            "YOY Returns: 0.35%\n",
            "YOY Std: +- 0.03%\n",
            "GT Yoy: 0.61%\n",
            "Plot filepath parent dir: data/results\n",
            "pair_tup_str: (USIG,IEI)\n",
            "  \n",
            "Using device: cuda\n",
            "Split sizes — train: 3524, dev: 250, test: 252\n",
            "Epoch 010 | train MSE 0.640057 | val MSE 0.594507\n",
            "Epoch 020 | train MSE 0.187081 | val MSE 0.044786\n",
            "Epoch 030 | train MSE 0.100824 | val MSE 0.027316\n",
            "Epoch 040 | train MSE 0.064481 | val MSE 0.023687\n",
            "Epoch 050 | train MSE 0.047009 | val MSE 0.023098\n",
            "Epoch 060 | train MSE 0.036718 | val MSE 0.016306\n",
            "Epoch 070 | train MSE 0.029969 | val MSE 0.013600\n",
            "Epoch 080 | train MSE 0.026241 | val MSE 0.012072\n",
            "Epoch 090 | train MSE 0.022536 | val MSE 0.010274\n",
            "Epoch 100 | train MSE 0.021353 | val MSE 0.008682\n",
            "Epoch 110 | train MSE 0.020006 | val MSE 0.008046\n",
            "Epoch 120 | train MSE 0.017997 | val MSE 0.007273\n",
            "Epoch 130 | train MSE 0.016801 | val MSE 0.006733\n",
            "Epoch 140 | train MSE 0.016517 | val MSE 0.006374\n",
            "Epoch 150 | train MSE 0.015544 | val MSE 0.006847\n",
            "Epoch 160 | train MSE 0.015321 | val MSE 0.006026\n",
            "Epoch 170 | train MSE 0.021393 | val MSE 0.006455\n",
            "Epoch 180 | train MSE 0.016426 | val MSE 0.011693\n",
            "Epoch 190 | train MSE 0.017554 | val MSE 0.005396\n",
            "Epoch 200 | train MSE 0.015780 | val MSE 0.004679\n",
            "Epoch 210 | train MSE 0.015854 | val MSE 0.004841\n",
            "Epoch 220 | train MSE 0.017183 | val MSE 0.004643\n",
            "Epoch 230 | train MSE 0.016292 | val MSE 0.006730\n",
            "Epoch 240 | train MSE 0.015109 | val MSE 0.006250\n",
            "Epoch 250 | train MSE 0.015417 | val MSE 0.006779\n",
            "Epoch 260 | train MSE 0.015487 | val MSE 0.006684\n",
            "Epoch 270 | train MSE 0.015773 | val MSE 0.004535\n",
            "Epoch 280 | train MSE 0.013820 | val MSE 0.007787\n",
            "Epoch 290 | train MSE 0.014134 | val MSE 0.010266\n",
            "Epoch 300 | train MSE 0.014151 | val MSE 0.004878\n",
            "\n",
            "Validation MSE: 0.032248013588229256\n",
            "Test MSE: 0.14911798751314825\n",
            "YOY Returns: 0.16%\n",
            "YOY Std: +- 0.09%\n",
            "GT Yoy: 0.25%\n",
            "Plot filepath parent dir: data/results\n",
            "pair_tup_str: (IFGL,BND)\n",
            "  \n",
            "Using device: cuda\n",
            "Split sizes — train: 3524, dev: 250, test: 252\n",
            "Epoch 010 | train MSE 0.660176 | val MSE 5.386897\n",
            "Epoch 020 | train MSE 0.124275 | val MSE 0.876783\n",
            "Epoch 030 | train MSE 0.042481 | val MSE 0.041149\n",
            "Epoch 040 | train MSE 0.028590 | val MSE 0.017911\n",
            "Epoch 050 | train MSE 0.019255 | val MSE 0.021234\n",
            "Epoch 060 | train MSE 0.014923 | val MSE 0.024365\n",
            "Epoch 070 | train MSE 0.013235 | val MSE 0.026591\n",
            "Epoch 080 | train MSE 0.012694 | val MSE 0.040053\n",
            "Epoch 090 | train MSE 0.011097 | val MSE 0.031175\n",
            "Epoch 100 | train MSE 0.010994 | val MSE 0.031701\n",
            "Epoch 110 | train MSE 0.010806 | val MSE 0.034279\n",
            "Epoch 120 | train MSE 0.009432 | val MSE 0.036191\n",
            "Epoch 130 | train MSE 0.008997 | val MSE 0.038357\n",
            "Epoch 140 | train MSE 0.008548 | val MSE 0.022816\n",
            "Epoch 150 | train MSE 0.008606 | val MSE 0.034720\n",
            "Epoch 160 | train MSE 0.007807 | val MSE 0.032501\n",
            "Epoch 170 | train MSE 0.013308 | val MSE 0.034567\n",
            "Epoch 180 | train MSE 0.010216 | val MSE 0.037220\n",
            "Epoch 190 | train MSE 0.008621 | val MSE 0.017951\n",
            "Epoch 200 | train MSE 0.007985 | val MSE 0.005887\n",
            "Epoch 210 | train MSE 0.008030 | val MSE 0.020080\n",
            "Epoch 220 | train MSE 0.008313 | val MSE 0.020871\n",
            "Epoch 230 | train MSE 0.008558 | val MSE 0.029964\n",
            "Epoch 240 | train MSE 0.008867 | val MSE 0.031000\n",
            "Epoch 250 | train MSE 0.008988 | val MSE 0.033456\n",
            "Epoch 260 | train MSE 0.008559 | val MSE 0.006979\n",
            "Epoch 270 | train MSE 0.008318 | val MSE 0.014287\n",
            "Epoch 280 | train MSE 0.008315 | val MSE 0.012670\n",
            "Epoch 290 | train MSE 0.008466 | val MSE 0.005141\n",
            "Epoch 300 | train MSE 0.007539 | val MSE 0.010616\n",
            "\n",
            "Validation MSE: 0.41072650361183155\n",
            "Test MSE: 0.4809087554402606\n",
            "YOY Returns: 15.78%\n",
            "YOY Std: +- 0.31%\n",
            "GT Yoy: 16.05%\n",
            "Plot filepath parent dir: data/results\n",
            "pair_tup_str: (IFGL,SMH)\n",
            "  \n",
            "Using device: cuda\n",
            "Split sizes — train: 3524, dev: 250, test: 252\n",
            "Epoch 010 | train MSE 0.641204 | val MSE 0.511296\n",
            "Epoch 020 | train MSE 0.192388 | val MSE 0.038414\n",
            "Epoch 030 | train MSE 0.106265 | val MSE 0.025747\n",
            "Epoch 040 | train MSE 0.068742 | val MSE 0.021997\n",
            "Epoch 050 | train MSE 0.048952 | val MSE 0.020405\n",
            "Epoch 060 | train MSE 0.038476 | val MSE 0.014409\n",
            "Epoch 070 | train MSE 0.030766 | val MSE 0.012148\n",
            "Epoch 080 | train MSE 0.026968 | val MSE 0.011053\n",
            "Epoch 090 | train MSE 0.023102 | val MSE 0.009110\n",
            "Epoch 100 | train MSE 0.022017 | val MSE 0.007741\n",
            "Epoch 110 | train MSE 0.020466 | val MSE 0.007368\n",
            "Epoch 120 | train MSE 0.018334 | val MSE 0.007101\n",
            "Epoch 130 | train MSE 0.016950 | val MSE 0.006146\n",
            "Epoch 140 | train MSE 0.016827 | val MSE 0.005699\n",
            "Epoch 150 | train MSE 0.015474 | val MSE 0.007148\n",
            "Epoch 160 | train MSE 0.015430 | val MSE 0.005421\n",
            "Epoch 170 | train MSE 0.020738 | val MSE 0.021235\n",
            "Epoch 180 | train MSE 0.017202 | val MSE 0.004959\n",
            "Epoch 190 | train MSE 0.018200 | val MSE 0.011223\n",
            "Epoch 200 | train MSE 0.016800 | val MSE 0.006120\n",
            "Epoch 210 | train MSE 0.017188 | val MSE 0.005032\n",
            "Epoch 220 | train MSE 0.018018 | val MSE 0.010610\n",
            "Epoch 230 | train MSE 0.015417 | val MSE 0.005003\n",
            "Epoch 240 | train MSE 0.015440 | val MSE 0.005590\n",
            "Epoch 250 | train MSE 0.017231 | val MSE 0.008593\n",
            "Epoch 260 | train MSE 0.016782 | val MSE 0.011819\n",
            "Epoch 270 | train MSE 0.016773 | val MSE 0.007833\n",
            "Epoch 280 | train MSE 0.013799 | val MSE 0.010537\n",
            "Epoch 290 | train MSE 0.014316 | val MSE 0.005039\n",
            "Epoch 300 | train MSE 0.014368 | val MSE 0.005430\n",
            "\n",
            "Validation MSE: 0.03245427703071042\n",
            "Test MSE: 0.22386766979794387\n",
            "YOY Returns: 0.01%\n",
            "YOY Std: +- 0.08%\n",
            "GT Yoy: -0.27%\n",
            "Plot filepath parent dir: data/results\n",
            "pair_tup_str: (IFGL,MBB)\n",
            "  \n",
            "Using device: cuda\n",
            "Split sizes — train: 3524, dev: 250, test: 252\n",
            "Epoch 010 | train MSE 0.658604 | val MSE 5.310045\n",
            "Epoch 020 | train MSE 0.122515 | val MSE 0.850368\n",
            "Epoch 030 | train MSE 0.041967 | val MSE 0.041559\n",
            "Epoch 040 | train MSE 0.028167 | val MSE 0.019629\n",
            "Epoch 050 | train MSE 0.018991 | val MSE 0.023050\n",
            "Epoch 060 | train MSE 0.014796 | val MSE 0.025638\n",
            "Epoch 070 | train MSE 0.013097 | val MSE 0.028445\n",
            "Epoch 080 | train MSE 0.012632 | val MSE 0.042529\n",
            "Epoch 090 | train MSE 0.011024 | val MSE 0.033867\n",
            "Epoch 100 | train MSE 0.010964 | val MSE 0.032684\n",
            "Epoch 110 | train MSE 0.010706 | val MSE 0.035742\n",
            "Epoch 120 | train MSE 0.009417 | val MSE 0.036917\n",
            "Epoch 130 | train MSE 0.008989 | val MSE 0.039280\n",
            "Epoch 140 | train MSE 0.008437 | val MSE 0.025029\n",
            "Epoch 150 | train MSE 0.008483 | val MSE 0.035058\n",
            "Epoch 160 | train MSE 0.007839 | val MSE 0.034346\n",
            "Epoch 170 | train MSE 0.010578 | val MSE 0.015568\n",
            "Epoch 180 | train MSE 0.010740 | val MSE 0.031791\n",
            "Epoch 190 | train MSE 0.010177 | val MSE 0.012620\n",
            "Epoch 200 | train MSE 0.009552 | val MSE 0.011660\n",
            "Epoch 210 | train MSE 0.009668 | val MSE 0.006067\n",
            "Epoch 220 | train MSE 0.010781 | val MSE 0.016690\n",
            "Epoch 230 | train MSE 0.008274 | val MSE 0.026746\n",
            "Epoch 240 | train MSE 0.008150 | val MSE 0.009164\n",
            "Epoch 250 | train MSE 0.008999 | val MSE 0.022952\n",
            "Epoch 260 | train MSE 0.008387 | val MSE 0.006151\n",
            "Epoch 270 | train MSE 0.008725 | val MSE 0.005227\n",
            "Epoch 280 | train MSE 0.008067 | val MSE 0.018294\n",
            "Epoch 290 | train MSE 0.009800 | val MSE 0.015011\n",
            "Epoch 300 | train MSE 0.008569 | val MSE 0.012498\n",
            "\n",
            "Validation MSE: 0.41049574040503756\n",
            "Test MSE: 0.191706775283045\n",
            "YOY Returns: -100.00%\n",
            "YOY Std: +- 0.00%\n",
            "GT Yoy: -100.00%\n",
            "Plot filepath parent dir: data/results\n",
            "pair_tup_str: (IFGL,SOXX)\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(results_to_latex(results_transformer_2023))"
      ],
      "metadata": {
        "id": "Wdq1ulF_ehRw",
        "outputId": "8ec5108e-350b-4c1b-8689-4a2748a4fffd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Wdq1ulF_ehRw",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\\begin{table}[h]\n",
            "\\centering\n",
            "\\small\n",
            "\\resizebox{\\textwidth}{!}{\n",
            "\\begin{tabular}{lcccccc}\n",
            "\\toprule\n",
            "Pair & Cointegration Score & val MSE & test MSE & YoY Returns (std) & \\makecell{Theoretical Return\\\\Under Perfect\\\\Information} & Return Score \\\\\n",
            "\\midrule\n",
            "1. (PFF,EMB) & $2.82\\times 10^{-4}$ & 0.06810 & 0.16529 & $0.09\\% \\pm 0.01\\%$ & -0.06\\% & 1.00 \\\\\n",
            "2. (IFGL,EMB) & $7.70\\times 10^{-4}$ & 0.03479 & 0.09328 & $0.43\\% \\pm 0.07\\%$ & 0.65\\% & 1.00 \\\\\n",
            "3. (IGF,DVY) & $1.17\\times 10^{-3}$ & 0.15914 & 0.08200 & TLOE* & TLOE* & nan \\\\\n",
            "4. (IGIB,IEI) & $1.25\\times 10^{-3}$ & 0.02616 & 0.06271 & $0.48\\% \\pm 0.03\\%$ & 0.50\\% & 1.00 \\\\\n",
            "5. (DVY,PEY) & $1.57\\times 10^{-3}$ & 0.12656 & 0.05569 & $0.21\\% \\pm 0.01\\%$ & 0.15\\% & 1.00 \\\\\n",
            "6. (USIG,IEI) & $1.67\\times 10^{-3}$ & 0.04195 & 0.18978 & $0.35\\% \\pm 0.03\\%$ & 0.61\\% & 1.00 \\\\\n",
            "7. (IFGL,BND) & $1.93\\times 10^{-3}$ & 0.03225 & 0.14912 & $0.16\\% \\pm 0.09\\%$ & 0.25\\% & 1.00 \\\\\n",
            "8. (IFGL,SMH) & $2.58\\times 10^{-3}$ & 0.41073 & 0.48091 & $15.78\\% \\pm 0.31\\%$ & 16.05\\% & 1.00 \\\\\n",
            "9. (IFGL,MBB) & $2.63\\times 10^{-3}$ & 0.03245 & 0.22387 & $0.01\\% \\pm 0.08\\%$ & -0.27\\% & 1.00 \\\\\n",
            "10. (IFGL,SOXX) & $2.70\\times 10^{-3}$ & 0.41050 & 0.19171 & TLOE* & TLOE* & nan \\\\\n",
            "\\bottomrule\n",
            "\\end{tabular}\n",
            "}\n",
            "\\caption{Model performance and return statistics for all tested pairs.}\n",
            "\\end{table}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, output in enumerate(all_outputs_transformer_2022):\n",
        "    gt_test_series, forecast_test_series = output['gt_test_shortened_series'], output['forecast_test_shortened_series']\n",
        "    plot_comparison(gt_test_series, forecast_test_series, gt_test_series.index, verbose=True, filename_base=f\"all_outputs_transformer_2022_{i}\")"
      ],
      "metadata": {
        "id": "OKa8N78glswr"
      },
      "id": "OKa8N78glswr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Time-MoE"
      ],
      "metadata": {
        "id": "O23--vU4NKL6"
      },
      "id": "O23--vU4NKL6"
    },
    {
      "cell_type": "code",
      "source": [
        "# Hard code hyperparameters based on results above\n",
        "hyperparam_kwargs = dict(\n",
        "  ## optimized hyperparams: learning algorithm ##\n",
        "  learning_rate=1e-4,\n",
        "  min_learning_rate=5e-5,\n",
        "  warmup_ratio=0.0,\n",
        "  weight_decay=0.1,\n",
        "  global_batch_size=64, # (just the batch size) other option would be micro_batch_size, which sets batch size per device\n",
        "  adam_beta1=0.9,\n",
        "  adam_beta2=0.95,\n",
        "  adam_epsilon=1e-8,\n",
        "  ## optimized hyperparams: learning algorithm ##\n",
        ")\n",
        "\n",
        "### Year-specific data ###\n",
        "startDateStr = '2008-01-01'\n",
        "end_year = 2022\n",
        "endDateStr = f'{end_year}-12-31'\n",
        "startDateStrTest = f'{end_year}-01-01'\n",
        "endDateStrTest = f'{end_year}-12-31'\n",
        "train_frac, dev_frac = _get_train_dev_frac(startDateStr, endDateStr, startDateStrTest, endDateStrTest)\n",
        "\n",
        "instrumentIdsNASDAQandNYSE = load_cached_etf_tickers()\n",
        "data = gather_data_cached_using_truncate(startDateStr, endDateStr, instrumentIdsNASDAQandNYSE, cache_dir='../src/data/cache')\n",
        "data_close_filtered_1, data_open_filtered_1, data_high_filtered_1, data_low_filtered_1, data_vol_filtered_1, data_original_format_filtered_1 = step_1_filter_remove_nans(data['close'], data['open'], data['high'], data['low'], data['vol'], data)\n",
        "data_close_filtered_2, data_open_filtered_2, data_high_filtered_2, data_low_filtered_2, data_vol_filtered_2, data_original_format_filtered_2 = step_2_filter_liquidity(data_close_filtered_1, data_open_filtered_1, data_high_filtered_1, data_low_filtered_1, data_vol_filtered_1, data_original_format_filtered_1)\n",
        "\n",
        "pairs_data_filtered = gather_pairs_data_cached(startDateStr, endDateStr, instrumentIdsNASDAQandNYSE, cache_dir='../src/data/cache')\n",
        "if pairs_data_filtered is None:\n",
        "  scores, pvalues, pairs = find_cointegrated_pairs(data_original_format_filtered_2)\n",
        "  pairs_data = {key:value[1]  for (key, value) in pairs.items()}\n",
        "  pairs_data = sorted(pairs_data.items(), key=lambda x: x[1])\n",
        "  pairs_data_filtered = filter_pairs_data(pairs_data) # filter based on cointegration in such a way that we can simply pick the highest pair of stocks in the list.\n",
        "  save_pairs_data_filtered(pairs_data_filtered, startDateStr, endDateStr, instrumentIdsNASDAQandNYSE, cache_dir='../src/data/cache')\n",
        "### Year-specific data ###\n",
        "\n",
        "### OPTIONAL: define worfklow here for debugging ###\n",
        "### OPTIONAL: define worfklow here for debugging ###\n",
        "\n",
        "# Gather results for 2022\n",
        "results_timemoe_2022 = []\n",
        "all_outputs_timemoe_2022 = []\n",
        "num_results = min(len(pairs_data_filtered), 10)\n",
        "for i in tqdm(range(num_results), desc = \"Gathering [...]\"):\n",
        "    ticker_a, ticker_b = pairs_data_filtered[i][0][0], pairs_data_filtered[i][0][1]\n",
        "    pair_tup_str_current = f\"({ticker_a},{ticker_b})\"\n",
        "    pairs_timeseries_df = combine_pairs_data(data_close_filtered_2, data_open_filtered_2, data_high_filtered_2, data_low_filtered_2, data_vol_filtered_2, ticker_a, ticker_b)\n",
        "    output_returns = get_gt_yoy_returns_test_dev(pairs_timeseries_df, dev_frac, train_frac, look_back=20)\n",
        "    gt_yoy, gt_yoy_for_dev_dataset = output_returns['gt_yoy_test'], output_returns['gt_yoy_dev']\n",
        "    output_model = execute_timemoe_workflow(pairs_timeseries_df, verbose=verbose, pair_tup_str=pair_tup_str_current, train_frac=train_frac, dev_frac=dev_frac, return_datasets=return_datasets, **hyperparam_kwargs)\n",
        "    # print(output_model\n",
        "    yoy_str = f\"{output_model['yoy_mean'] * 100:.2f}% +- {output_model['yoy_std'] * 100:.2f}%\"\n",
        "    returns_score = return_score(output_model['yoy_mean'], gt_yoy)\n",
        "    cointegration_score = pairs_data_filtered[i][1]\n",
        "    results_timemoe_2022.append((pair_tup_str_current, cointegration_score, output_model['val_mse'], output_model['test_mse'], yoy_str, gt_yoy, returns_score)) # (pair, cointegration_score, val, test, yoy_str, gt_yoy, returns_score)\n",
        "    all_outputs_timemoe_2022.append(output_model)\n"
      ],
      "metadata": {
        "id": "7fAed6iSN6kS"
      },
      "id": "7fAed6iSN6kS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, output in enumerate(all_outputs_timemoe_2022):\n",
        "    gt_test_series, forecast_test_series = output['gt_test_shortened_series'], output['forecast_test_shortened_series']\n",
        "    plot_comparison(gt_test_series, forecast_test_series, gt_test_series.index, verbose=True, filename_base=f\"all_outputs_timemoe_2022_{i}\")"
      ],
      "metadata": {
        "id": "xwHmPM-SoErh"
      },
      "id": "xwHmPM-SoErh",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "61285f11a1dd4fc6b68c1b092eeedc55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f4a210a4e180473a8a412fc95971fe66",
              "IPY_MODEL_d551dbf3fe6545e1bae2fc6613ed16b9",
              "IPY_MODEL_b270c199d43a47a0aa99bc0a65a02f35"
            ],
            "layout": "IPY_MODEL_28c6cfccc5bf484d8490c02a808becfe"
          }
        },
        "f4a210a4e180473a8a412fc95971fe66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e650f394bcbd4356955e44573cd71304",
            "placeholder": "​",
            "style": "IPY_MODEL_98bf5640cc26458f82b213f3224a414e",
            "value": "Gathering [...]: 100%"
          }
        },
        "d551dbf3fe6545e1bae2fc6613ed16b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2daa4af64c724ffaa6683981ff06b564",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6621540de689465a9d13fa3f12b2908c",
            "value": 10
          }
        },
        "b270c199d43a47a0aa99bc0a65a02f35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1301482167b640f2952dc0282b955e49",
            "placeholder": "​",
            "style": "IPY_MODEL_8dae436fde6d414abfa04302db8e0520",
            "value": " 10/10 [25:02&lt;00:00, 150.56s/it]"
          }
        },
        "28c6cfccc5bf484d8490c02a808becfe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e650f394bcbd4356955e44573cd71304": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98bf5640cc26458f82b213f3224a414e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2daa4af64c724ffaa6683981ff06b564": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6621540de689465a9d13fa3f12b2908c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1301482167b640f2952dc0282b955e49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8dae436fde6d414abfa04302db8e0520": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}